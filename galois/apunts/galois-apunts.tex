\documentclass[12pt,oneside]{book}

\input{preamble-apunts.tex}
\input{commands-galois.tex}


\graphicspath{{./figs/}}
\newcommand{\dummyfig}[1]{
  \centering
  \fbox{
    \begin{minipage}[c][0.33\textheight][c]{0.5\textwidth}
      \centering{\ttfamily #1}
    \end{minipage}
  }
}

\title{Galois Theory}
\author{Arnau Mas}
\date{2019}

\begin{document}
\maketitle

\frontmatter
\pagestyle{plain}
These are notes gathered during the subject \emph{Teoria de Galois} as taught by Francesc Perera between September 2019 and January 2020.

\mainmatter

\chapter{Preliminaries}
\section{The solution of low degree polynomial equations}
It is surely well-known to any aspiring mathematician that there exist no general formulas for the solutions of polynomial equations of degree five and higher. This implies, of course, that such formulas exist for equations of degree fourth and lower. Indeed, the solution of linear equations is trivial and the quadratic formula should be more than well-known by this point. In this section we present a derivation of the solutions of both the quadratic and cubic equations. 

\subsection{The quadratic equation}
First, note that we can, without loss of generality, assume that we are working with a monic equation since we may always divide through by the leading coefficient to obtain an equation with the same solutions and with leading coefficient 1. Thus, we are trying to solve \( x^2 + bx + c = 0 \). The standard method is completing the square, that is to write \( x^2 + bx + c \) as a square, and one achieves so by adding and substracting \( \frac{b^2}{4} \):
\begin{equation*}
	x^2 + bx + c = x^2 + bx + \frac{b^2}{4} - \frac{b^2}{4} + c = \left(x + \frac{b}{2}\right)^2 - \frac{b^2}{4} + c.
\end{equation*}
Then the solutions to the original equation must satisfy
\begin{equation*}
	\left(x + \frac{b}{2}\right)^2 = \frac{b^2}{4} - c.
\end{equation*}
If the term on the right is not a square in the field we are working over then there are no solutions in that field. On the other hand, if it is a square then it has two square roots and the solutions to the original equation are
\begin{equation*}
	x = - \frac{b}{2} \pm \frac{1}{2}\sqrt{b^2 - 4c},
\end{equation*}
which is the well known quadratic formula.

\subsection{The cubic equation}
Less well-known is the formula for the solutions of the cubic equation. Whereas the quadratic formula had been known to the greeks and babylonians, the cubic formula was discovered later during the fifteenth century. There were several italian mathematicians involved in its discovery: Cardano, Ferrari and del Ferro among others. The question of the original discoverer is a contemptious matter. 

The first step in the solution is a change of variables to eliminate the quadratic term. If \( x = y - \frac{1}{3}b \) then the original (monic) polynomial becomes
\begin{align*}
	x^3 + bx^2 + cx + d &= y^3 - by^2 + \frac{1}{3}b^2 y - \frac{1}{27}b^3 + by^2 - \frac{2}{3}b^2y + \frac{1}{9}b^3 + cy - \frac{1}{3}bc + d \\
											&= y^3 + \left(c - \frac{1}{3}b^2 \right)y + \frac{2}{27}b^3 - \frac{1}{3}bc + d.
\end{align*}
Therefore we only need to be able to solve cubics of the form \( x^3 + px + q = 0 \). 

The basic trick is similar to completing the square. We have the identity
\begin{equation*}
	(u+v)^3 = u^3 + 3u^2v + 3uv^2 + v^3 = u^3 + 3uv(u+v) + v^3,
\end{equation*}
and rearranging we obtain \( (u+v)^3 - 3uv(u+v) - u^3 - v^3 = 0 \). One then notices that there are cubic and linear terms in \( u+v \) but no quadratic terms. Then one tries to solve for \( u \) and \( v \) to then obtain \( x \) as \( u+v \). \( u \) and \( v \) must satisfy \( -3uv = p \) and \( -u^3 - v^3 = q \). Multiplying this second condition by \( u^3 \) we get
\begin{equation*}
	u^6 + qu^3 + u^3v^3 = 0,
\end{equation*}
and using the fact that \( uv = -\frac{1}{3}p \) we arrive at
\begin{equation*}
	u^6 + qu^3 - \frac{p^3}{27} = 0,
\end{equation*}
which is quadratic in \( u^3 \). If we instead had multiplied through by \( v^3 \) we would have arrived to the same equation for \( v^3 \) instead.

Up to now nothing we have done relied on any additional assumption on the field have been working over. From this point, however, the nature of the solutions will depend on the behaviour of radicals in the field in question. We will assume we are working in \( \C \). We can then solve for \( u^3 \) and \( v^3 \) to find
\begin{align*}
	u^3 &= -\frac{q}{2} \pm \sqrt{\frac{q^2}{4} + \frac{p^3}{27}} \\
	v^3 &= -\frac{q}{2} \pm \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}.
\end{align*}
The ambiguity with the signs is eliminated due to the fact that \( u^3 + v^3 = -q \) so we find the only good options are those in which the signs of the square root terms are opposite, so that they will cancel when added. Since we only care about the sum of \( u \) and \( v \) we might as well choose
\begin{equation*}
	u^3 = -\frac{q}{2} + \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}
\end{equation*}
and 
\begin{equation*}
	v^3 = -\frac{q}{2} - \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}.
\end{equation*}
There are three possibilities for \( u \) and three for \( v \). Indeed, every complex number has three roots and if \( a \) is one of them then so are \( \omega a \) and \( \omega^2 a \) where \( \omega = e^{\frac{2\pi}{3}i} \). Not every combination of them leads to a solution of the cubic ---if it were so we would have more than three roots and a cubic polynomial can only have three roots--- since they are constrained by the relation \( 3uv = -p \). So, once we find \( u \) and \( v \) that satisfy this then so will \( \omega u \) and \( \omega^2 v \), as well as \( \omega^2 u \) and \( \omega v \) since \( \omega^3 = 1 \).

All together, one of the solutions to the cubic \( x^3 + px + q = 0 \) is given by
\begin{equation*}
	x = \sqrt[3]{-\frac{q}{2} + \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}} + \sqrt[3]{-\frac{q}{2} - \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}},
\end{equation*}
which is known as Cardano's formula. If we undo the change of variable to eliminate the quadratic term and use \( p = c - \frac{1}{3}b^2 \) and \( q = \frac{2}{27}b^3 - \frac{1}{3}bc + d \) then we obtain the cubic formula in all of its glory:
\begin{align*}
	x = -\frac{b}{3} &+ \sqrt[3]{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right) + \sqrt{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right)^2 + \left(\frac{c}{3} - \frac{b^2}{9}\right)^3}} \\
									 & +\sqrt[3]{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right) - \sqrt{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right)^2 + \left(\frac{c}{3} - \frac{b^2}{9}\right)^3}}.
\end{align*}


\section{Polynomial rings}
The study of polynomial rings is particularly important in Galois theory since they play an important role in many of the constructions and definitions of the theory. Of special relevance is the study of their quotient rings.  

\subsection{The universal property of polynomial rings}
Given a ring\footnote{We will always assume that we are dealing with commutative rings with identity unless otherwise stated.} \( R \) its polynomial ring \( R[x] \) can be defined in various ways. Most commonly, the elements of \( R[x] \) are said to be ``formal sums'' of the form
\begin{equation*}
	\sum_{k = 1}^{n} a_k x^k 
\end{equation*}
where the \( a_k \) are elements of \( R \) and \( x \) is refered to as an ``indeterminate'' or some other similarly ambiguous term. This definition may feel imprecise to the more technically inclined reader. A more exact definition of \( R[x] \) is as the set of sequences of elements of \( R \) with finite suport. The sum is defined pointwise and the product is defined in a convoluted manner which correspond to the way one would multiply polynomials with repeated application of the distribuitive law. Then there is a canonical inclusion \( R \into R[x] \) by way of \( a \mapsto (a,0, \cdots) \). And if we define \( x \) to be the sequence \( (0,1, \cdots) \) then we recover the more standard presentation of \( R[x] \).

This discussion, however, is about what a programmer would call the implementation details and it misses the bigger picture. How \( R[x] \) is constructed is not really what is relevant here. It is much more illuminating to think about what we want out of \( R[x] \) instead. For one, \( R[x] \) should contain \( R \). We could require \( R \subseteq R[x] \), but let's be more general and allow for an injective morphism \( \iota \colon R \into R[x] \) that picks out a copy of \( R \) inside \( R[x] \). The other important aspect of \( R[x] \) is the indeterminate. The way to formalize it is with what is known as a universal property: for any morphism \( \phi \colon R \to S \) and distinguished element \( s \in S \) there is a unique morphism \( \tilde{\phi} \colon R[x] \to S \) such that \( \tilde{\phi} \circ \iota = \phi \) and \( \tilde{\phi}(x) = s \). That is, \( \tilde{\phi} \) must agree with \( \phi \) on \( R \) and it must send \( x \) to \( s \). This does indeed uniquely determine \( \tilde{\phi} \). It can be shown that this determines \( R[x] \) up to unique isomorphism, meaning there is a unique isomorphism between any two rings that satisfy the universal property. So you can construct \( R[x] \) in whatever way you like so long as the result satisfies the universal property.

One last remark about polynomial rings in many variables: once we have defined the polynomial ring of a ring \( \R \), we can then proceed inductively to define the polynomial ring on \( n \) variables as \( R[x_1, \cdots, x_n] = R[x_1, \cdots, x_{n-1}][x_n] \). Polynomial rings in more than one variables also satisfy a universal property, which is essentially the same as before except now we have to specify where \( \tilde{\phi} \) sends all of the \( x_i \).

This universal property is not just of theoretical importance, it is also extermely practical. Indeed, it provides a very quick way of specifying morphisms on a polynomial ring. All you need is to specify how it acts on the coeficients and where it sends the indeterminate and you're done.

\begin{example}\label{exe:morphisms on polynomial rings}
	These are various examples of morphisms defined on a polynomial ring making use of the universal property.
	\begin{points}
	\item For any element \( \alpha \in R \) we can define the evaluation morphism \( \ev{\alpha} \colon R[x] \to R \) such that \( \ev{\alpha}\rest{R} = \id_R \) and \( \ev{\alpha}(x) = \alpha \). That is, simply evaluate a polynomial on the element \( \alpha \in R \). The element we evaluate at need not be an element of \( R \), in fact it can be an element of any ring which contains \( R \). 

	\item A trick that is often used when working with polynomials is a change of variable. This idea can be made formal in terms of an automorphism of \( R[x] \). Say we wanted to make the change \( y = x+1 \), or \( x = y-1 \). This amounts to defining a morphism \( \phi \colon R[x] \to R[x] \) such that \( \phi \rest{R} = \id_R \) and \( \phi(x) = y-1 \). \( \phi \) does not move the coeficients and changes \( x \) to \( y-1 \). More generally, we could perform a change of the form \( \phi(x) = ay + b \). In order for \( \phi \) to be an isomorphism, \( a \) must be invertible. Indeed, \( \phi^{-1} \) sends \( x \) to \( a^{-1}(x - b) \). Then, when showing that a certain polynomial is irreducible, for instance, we can do any change of variable we please and rest assured that the resulting polynomial will be irreducible if and only if the original one was irreducible, for irreducibility is preserved under isomorphism.	
	\item Any permutation \( \sigma \in \S_n \) induces an isomorphism on \( R[x, \dots, x_n] \) by permuting the variables according to \( \sigma \). Indeed, let \( \phi_{\sigma} \) be the unique morphism that is the identity on \( R \) and such that \( \phi_{\sigma}(x_i) = x_{\sigma(i)} \). You can check that \( \phi_{\sigma} \circ \phi_{\tau} = \phi_{\sigma \circ \tau} \). And as a corollary \( \phi_{\sigma}^{-1} = \phi_{\sigma^{-1}} \). This is in fact an action of the symmetric group \( \S_n \) on \( R[x_1, \cdots, x_n] \). The polynomials invariant under this action, \( R[x_1, \cdots, x_n]^{\S_n} \) are known as the \emph{symmetric polynomials}.
	\end{points}
\end{example}

\chapter{Field extensions}
\section{Definition and examples}
\begin{definition}[Field extension]
	We say a field \( F \) is an \emph{extension} of a field \( K \) if \( K \) is a
	subfield of \( F \). More generally, given any field \( K \) and an injective morphism
	\( 	\iota \colon K \hookrightarrow F \) we will refer to the situation as a field
	extension and often identify \( K \) with \( \iota(K) \) and simply write \( K \subseteq F \). 
\end{definition}

There are some immediate examples of field extensions such as \( \R \subseteq \C \) and \(
\Q \subseteq \R \). In the following examples we detail the construction of three related
kinds of extensions.

\subsection{Simple extensions}\label{sec:simple extensions}
Say we already have an extension \( K \subseteq F \) and an element \( \alpha \in F \).
Then \( \alpha \) induces an evaluation morphism, \( \ev{\alpha} \colon K[x] \to F \). Since \(
K[x] \) is a PID there must exist a polynomial \( p(x) \in K[x] \) such that \(
\ker(\ev{\alpha}) = \gen{p(x)} \). If we denote \( \im(\ev{\alpha}) \) by \( K[\alpha] \)
we have, by the Isomorphism Theorem
\begin{equation*}
	K[\alpha] \cong K[x]/\gen{p(x)}.
\end{equation*}
We also have \( K \subseteq K[\alpha] \). Indeed, the image of a constant by \(
\ev{\alpha} \) is itself, so \( K \subseteq \im(\ev{\alpha}) = K[\alpha] \). We can then
consider the set \( K(\alpha) \) which is the union of \( K[\alpha] \) and the inverses of
all of its nonzero elements ---they exist since \( K[\alpha] \subseteq F \)---. This is
isomorphic to the field of fractions of \( K[\alpha] \). Thus we have \( K \subseteq K[\alpha]
\subseteq K(\alpha) \), meaning \( K(\alpha) \) is a field extension of \( K \). From the

Various things can happen with \( K(\alpha) \). For one, if \( \alpha \in K \)
then \( \im(\ev{\alpha}) = K[\alpha] = K \), which is to be expected since \( \alpha \)
was already in \( \alpha \). In this case then \( \ker(\ev{\alpha}) = \gen{x - \alpha)}
\), which is essentially the fact that a polynomial has \( \alpha \) as a root if and only
if it is divisible by \( (x - \alpha) \).

If \( \ev{\alpha} \) has a nontrivial kernel then it follows that its generator is
irreducible. Indeed, since \( K[x] / \gen{p(x)} \cong K[\alpha] \) and \( K[\alpha] \) is
a domain then \( p(x) \) is prime, and therefore irreducible. This means that \(
\gen{p(x)} \) is a maximal ideal and \( K[\alpha] \) is a field, so in this case \(
K[\alpha] = K(\alpha) \). If this is the case we say the element \( \alpha \) is \emph{algebraic}
over \( K \). The generator of \( \ker(\ev{\alpha}) \) is not unique, since any scalar
multiple of a generator is also a generator. However, there is always a unique
\emph{monic} generator, which is called the \emph{minimal polynomial of \( \alpha \) over
\( K \)}, written \( \irr{\alpha}{K} \) or simply \( \irre{\alpha} \) if the base field is
understood.

If, instead, \( \ev{\alpha} \) has a trivial kernel then \( K[\alpha] \cong K[x] / \set{0}
\cong K[x] \) and so \( K(\alpha) \cong K(x) \). This means that adding \( \alpha \) to \(
K \) is essentially like adding a free variable. We say \( \alpha \) is
\emph{transcendental} over \( K \). We will analyse the difference between this two cases
later on.

Extensions of this sort are called \emph{simple extensions} and \( \alpha \) is called a
\emph{primitive element} of the extension.

\subsection{Quotient of a polynomial ring by a maximal ideal}
This is a way of constructing what are essentially simple extensions without requiring the
prior existence of a primitive element in a larger extension.

The polynomial ring \( K[x] \) is a PID which means that the ideal generated by an irreducible
polynomial \( p(x) \), \( \gen{p(x)} \) is a maximal ideal. This in turn means that the
quotient \( F = K[x]/\gen{p(x)} \) is a field. Not only that, \( F \) is in fact a field
extension of \( K \). Let's see how we can construct an inclusion \( F \into K \).

We have at our disposal an inclusion \( \iota \colon K \into K[x] \) and a projection	\(
\pi \colon K[x] \onto F \). Since any two elements of \( K \) belong to different
equivalence classes the restriction of \( \pi \) to \( K \) is injective, which means the
composition \( \pi \circ \iota \colon K \to F \) is also injective. Thus \( F \) is an
extension of \( K \).

We may summarise this in the following lemma.
\begin{lemma}
	Let \( K \) be a field and \( p(x) \in K[x] \) an irreducible polynomial. Then the
	quotient \( K[x]/\gen{p(x)}  \) is a field extension of \( K \).
\end{lemma}

A number of extensions are of this form. Indeed, we have that \( \C \cong \R[x]/\gen{x^2 +
1} \) and the class of \( x \) is written \( i \). There is also the extension \(
\Q[x]/\gen{x^2 - 2} \), which is typically written \( \Q(\sqrt{2}) \). More generally, if
\( b \) is not a square in \( \Q \) then \( x^2 - b \) is irreducible and we have the
extension \( \Q(\sqrt{b}) = \Q[x]/\gen{x^2 - b} \).

By this process we have enlarged the field \( K \) by ``artificially'' adding a primitive
element. Indeed, if \( p(x) = \sum_{k = 0}^{n}a_k x^k  \) in the quotient we
have
\begin{equation}\label{eq:class of x is root}
	0 = \overline{p(x)} = \overline{\sum_{k = 0}^{n}a_k x^k } = \sum_{k = 0}^{n} a_k
	\overline{x}^k 
\end{equation}
so \( \bar{x} \), the class of \( x \), is a root of \( p(x) \). Note that in
\cref{eq:class of x is root} we abused notation and wrote what should have been \(
\overline{a_k} \) simply as \( a_k \). As we mentioned, the equivalence class of a
constant does not contain any other constant so we can, and will, get away with this abuse of
notation.

Conversely, a simple extension \( K(\alpha) \) is isomorphic to \(
K[x]/\gen{m_{\alpha}} \) if \( \alpha \) is algebraic, essentially by definition.

\subsection{Subfield generated by a set} \label{sec:generated subfield}
Given an existing extension \( K \subseteq F \) and a set \( S \subseteq F \) we define \(
K[S] \) to be the smallest subring of \( F \) containing \( K \) and \( X \), and then \(
K(S) \) as the result of adding to \( K[S] \) the inverses of all its nonzero elements.
This is, by construction, the smallest subfield of \( F \) that contains both \( K \) and
\( S \). Notice that \( K(\set{\alpha}) \) coincides with the simple extension \( K(\alpha) \) we
described in the previous section. Indeed, \( K(\alpha) \) is a subfield of \( F \) and
it contains \( K \) and \( \alpha \), so it contains, by definition \( K(\set{\alpha}) \).
On the other hand, it is clear that \( \im(\ev{\alpha}) = K[\alpha] \subseteq
K(\set{\alpha}) \) since they are linear combinations of powers of \( \alpha \) with
coefficients in \( K \). And since \( K(\set{\alpha}) \) is a field it contains the
inverses of nonzero \( K[\alpha] \), that is, it contains \( K(\alpha) \).

If the set \( S \) is finite, say \( S = \set{\alpha_1, \dots, \alpha_n} \) then we will
drop the brackets and simply write \( K(\alpha_1, \dots, \alpha_n) \) instead of \(
K(\set{\alpha_1, \dots, \alpha_n}) \). Furthermore, we have
\begin{equation*}
	K(\alpha_1, \dots, \alpha_n) = K(\alpha_1, \dots, \alpha_{n-1})(\alpha_n).
\end{equation*}
Indeed, \( K(\alpha_1, \dots, \alpha_{n-1})(\alpha_n) \) is, by definition, the smallest
field which contains \( K(\alpha_1, \dots, \alpha_{n-1}) \) and \( \alpha_n \). This
means it contains \( K \) and \( \alpha_1, \dots, \alpha_n \), so, by definition
\begin{equation*}
	K(\alpha_1, \dots, \alpha_n) \subseteq K(\alpha_1, \dots, \alpha_{n-1})(\alpha_n).
\end{equation*}
For the other inclusion, \( K(\alpha_1, \dots, \alpha_n) \) contains, \( K
\) and \( \alpha_1, \dots, \alpha_{n-1} \), which means that, by definition
\begin{equation*}
	K(\alpha_1, \dots, \alpha_{n-1}) \subseteq K(\alpha_1, \dots, \alpha_n).
\end{equation*}
And since \( \alpha_n \in K(\alpha_1, \dots, \alpha_n) \), again by definition
\begin{equation*}
	K(\alpha_1, \dots, \alpha_{n-1})(\alpha_n) \subseteq K(\alpha_1, \dots, \alpha_n).
\end{equation*}
This means that extensions of this kind are simply iterated simple extensions.

\section{Algebraic and Transcendental Extensions}
We already encountered the concept of an algebraic element and a transcendental element
when discussing simple extensions in \cref{sec:simple extensions}. We will formalise these
ideas in this section.

\begin{definition}[Algebraic and transcendental elements] \label{def:algebraic and
	transcendental element}
	Given an extension \( K \subseteq F \) we say an element \( \alpha \in F \) is
	\emph{algebraic over \( K \)} or simply \emph{algebraic} if it is the root of some
	(nonzero)	polynomial in	\( K[x] \). On the other hand, we say \( \alpha \) is
	\emph{transcendental	over K} or simply \emph{transcendental} if it is not algebraic,
	i.e. if there is no	polynomial in	\( K[x] \) that has \( \alpha \) as a root. 
\end{definition}

In \cref{sec:simple extensions} we said an element was algebraic when the evaluation
morphism it induced had a nontrivial kernel. This is equivalent to the definition we just
gave. Indeed, if the kernel of \( \ev{\alpha} \) is nontrivial there exists a nonzero
polynomial that has it as a root, so \( \alpha \) is algebraic in the sense of
\Cref{def:algebraic and transcendental element}. Conversely, if \( \alpha \) is the 
root of some nonzero polynomial then this polynomial is in \( \ker(\ev{\alpha}) \), thus
\( \alpha \) is algebraic in the sense of \cref{sec:simple extensions}. Similarly we can
show that an element is transcendental in the sense of \Cref{def:algebraic and
transcendental element} if and only if \( \ker(\ev{\alpha}) = \gen{0} \).

An important object associated to an algebraic element is its minimal polynomial, which we
have already encountered. We state its definition here for completeness' sake. 
\begin{definition}[Minimal polynomial]
	The \emph{minimal polynomial} of an element \( \alpha \in F \) over a field \( K \),
	where \( F \) is an extension \( K \) is the unique monic generator of \(
	\ker(\ev{\alpha}) \). It is written \( \irr{\alpha}{K} \) or simply \( \irre{\alpha} \)
	if the base field \( K \) is understood. It is sometimes also refered to as the
	\emph{irreducible polynomial} of \( \alpha \).
\end{definition}
The following gives a characterisation of the minimal polynomial
{\def\currentprefix{prop:characterisation of the minimal polynomial}
	\begin{proposition}[Characterisation of the minimal polynomial]\label{prop:characterisation of the minimal polynomial}
		Let \( K \subseteq F \) be a field extension and \( \alpha \in F \). If there is a monic
		polynomial \( p(x) \in K[x] \) such that \( p(\alpha) = 0 \) ---so \( \alpha \) is
		algebraic--- then the following are equivalent
		\begin{points}
		\item \locallabel{i} \( p(x) = \irre{\alpha}, \)
		\item \locallabel{ii} \( p(x) \) is irreducible,
		\item \locallabel{iii} \( p(x) \) divides any polinomial \( q(x) \in K[x] \) that has
			\( \alpha  \) as a root,
		\item \locallabel{iv} \( p(x) \) has degree smaller than that of any polinomial \(
			q(x) \in K[x] \) that has	\( \alpha  \) as a root.
		\end{points}
	\end{proposition}
	\begin{proof}
		The implication \localref{i}\( \implies \)\localref{ii} is the definition of the
		minimal polynomial. For the converse, note that \( p(x) \in \ker(\ev{\alpha}) \),
		which means \( \gen{p(x)} \subseteq \ker(\ev{\alpha}) \). Since \( p(x) \) is
		irreducible, \( \gen{p(x)} \) is maximal, which means either \( \ker(\ev{\alpha}) =
		\gen{p(x)} \) or \( \ker(\ev{\alpha}) = K[x] \). No evaluation map can ever be the
		zero map, since the constants always evaluate to themselves. This means it must be the
		case that
		\begin{equation*}
			\gen{p(x)} = \ker(\ev{\alpha})
		\end{equation*}
		and since \( p(x) \) is, by hypothesis, monic, it follows \( p(x) = \irre{\alpha} \).

		Let's show \localref{ii}\( \implies \)\localref{iii}. We know that \( p(x) \) is the
		minimal polynomial of \( \alpha \), thus \( \gen{p(x)} = \ker(\ev{\alpha}) \). If \(
		q(\alpha) = 0 \) we have that \( q(x) \in \ker(\ev{\alpha}) = \gen{p(x)} \) which
		means \( p(x) \) divides \( q(x) \).

		The implication \localref{ii}\( \implies \)\localref{iv} follows from the fact that if a
		polynomial divides another polynomial then it must have a smaller degree.

		Let's now show \localref{iv}\( \implies \)\localref{ii}. Suppose we can factor \( p(x)
		\) as
		\begin{equation*}
			p(x) = s(x)r(x).
		\end{equation*}
		Then
		\begin{equation*}
			0 = p(\alpha) = r(\alpha)s(\alpha).
		\end{equation*}
		This means that one of \( r(\alpha) \) or \( s(\alpha) \) must be zero. Say \(
		r(\alpha) = 0 \). Then, by hypothesis \( \deg(p(x)) \leq \deg(r(x)) \). On the other
		hand we also have \( \deg(r(x)) \leq \deg(p(x)) \) since \( r(x) \) divides \( p(x)
		\). Therefore \( \deg(p(x)) = \deg(r(x)) \) and so \( \deg(s(x)) = 0 \), which means
		it is a unit. If it had been \( s(\alpha)	\) we would have wound up showing that \(
		r(x) \) was a unit. This implies that \( p(x) \) is irreducible. 

		This concludes the proof.
	\end{proof}
}
\parbreak

The notions of algebraic and transcendental serve to make a distinction between two
classes of extensions.
\begin{definition}[Algebraic and transcendental extensions]
	We say an extension \( K \subseteq F \) is \emph{algebraic} if every element of \( F \) is
	algebraic over \( K \). On the other hand, if the extension is not algebraic ---i.e. there
	exists a transcendental element of \( F \)--- we say it is \emph{transcendental}.
\end{definition}


\section{Degree of an extension}
\subsection{Definition and properties}
If we have a field extension \( K \subseteq F \) then \( F \) is a \( K \)-vector space.
Indeed, the addition is the addition defined on \( F \) by virtue of being a field, as is
the multiplication by elements of \( K \). All of the vector space axioms follow
immediately from the fact that \( F \) is a field. This leads to the following definition
\begin{definition}[Degree of an extension]
	The \emph{degree} of a field extension \( K \subseteq F \) is the dimension of \( F \)
	as a vector space. We write it \( [F \colon K] \). An extension of finite degree is called \emph{finite}, otherwise it is called
	\emph{infinite}.
\end{definition}

We can calculate the degree of any simple extension directly from the definition.
\begin{proposition}[Degree of a simple extension] \label{prop:degree of a simple
	extension}
	The simple extension	\( \ext{K}{\alpha} \) is finite if and only if \( \alpha \) is
	algebraic over \( K \)\footnote{\( \alpha \) is understood to
	lie in some extension of \( K \).}. If it is finite then its degree is the degree of the
	minimal polynomial of \( \alpha \) over \( K \). That is,
	\begin{equation*}
		[K(\alpha) \colon K] = \deg(\irr{\alpha}{K}).
	\end{equation*}
\end{proposition}
\begin{proof}
	Let's assume \( \alpha \) is algebraic. We will show that \( 1, \alpha, \dots,
	\alpha^{n-1} \) is a basis for \( K(\alpha) \), where \( n \) is the degree of \(
	\irre{\alpha} \).

	Since \( \alpha \) is algebraic we know \( K[\alpha] = K(\alpha) \). And since \(
	K[\alpha]	\) is, by definition, \( \im(\ev{\alpha}) \) every element of \( K(\alpha) \)
	is a polyomial expression in \( \alpha \) with coefficients in \( K \). Say
	\begin{equation*}
		\irre{\alpha} = x^n + \sum_{k = 0}^{n-1}a_k x^k.
	\end{equation*}
	Then, since \( m_{\alpha}(\alpha) = 0 \) then
	\begin{equation} \label{eq:nth power in terms of lesser powers}
		\alpha^n = - \sum_{k = 0}^{n-1}a_k x^k.
	\end{equation}
	Using \cref{eq:nth power in terms of lesser powers} we can rewrite any linear combination
	of powers of \( \alpha \) as a linear combination of powers of \( \alpha \) less than \(
	n \). This means that \( 1, \alpha, \dots, \alpha^{n-1} \) span \( K(\alpha) \). 

	Let's now show that they are linearly independent. Say there were \( a_0, \dots a_{n-1}
	\in K \) such that
	\begin{equation*}
		\sum_{k = 0}^{n-1} a_k \alpha^k = 0.
	\end{equation*}
	This would translate to a polynomial \( q(x) = \sum_{k = 0}^{n-1} a_k x^k  \) that
	evaluates to \( 0 \) at \( \alpha \). Thus it would be divisible by \( \irre{\alpha} \),
	but since \( q(x) \) is of degree at most \( n-1 \) the only possibility is that \( q(x)
	\) is actually the zero polynomial. That means \( a_0 = \cdots = a_{n-1} = 0 \), which
	shows that \( 1, \alpha, \dots, \alpha^{n-1} \) are linearly independent.

	On the other hand, if \( \alpha \) is transcendental then \( K(\alpha) \) has infinite
	degree over \( K \). Indeed, since \( K(\alpha) \cong K(x) \) it contains a copy of \(
	K[x] \) which has infinite dimension as a \( K \)-vector space.
\end{proof}
A very similar argument shows that the degree of an extension of the form \(
K[x]/\gen{p(x)} \) where \( p(x) \) is irreducible is \( \deg{p(x)} \). Indeed, extensions
of this form are essentially simple extensions constructed without the need for the
primitive element to exist in a prior extension, the class of \( x \), \( \bar{x} \) plays its role.

\begin{example}
	With \cref{prop:degree of a simple extension} we can calculate the degree of various
	extensions.
	\begin{points}
	\item We have \( [\Q(\sqrt{2}) \colon \Q] = [\Q(\sqrt{3}) \colon \Q] = 2 \). Indeed, the
		minimal polynomial of \( \sqrt{2} \) over \( \Q \) is \( x^2 - 2 \) given that it is
		irreducible over \( \Q \) since it has no roots. Similarly, the minimal polynomial of
		\( \sqrt{3} \) is \( x^2 - 3 \).
	\item Since the complex numbers have dimension 2 as a \( \R \)-vector space then \( [\C
		\colon \R ] = 2 \). Another way to show this is by noting that the minimal
		polynomial of \( i \) over \( \R \) is \( x^2 + 1 \) and \( \C = \R(i) \). By the same
		argument, \( [\Q(i) \colon \Q] = 2 \) since \( x^2 + 1 \) is also the minimal
		polynomial of \( i \) over \( \Q \).
	\item It is known that \( \pi \) and \( e \) are transcendental over the rationals, with
		proofs due to Lindemann and Hermite respectively. This means that both \(
		\Q(\pi) \) and \( \Q(e) \) are infinite. Consequently, since both extensions are
		contained within the reals it follows that \( \R \) is also infinite over \( \Q \).
	\item Let's calculate \( \ext{\Q}{\sqrt{2} + \sqrt{3}} \). We have 
		\begin{equation*}
			(\sqrt{2} + \sqrt{3})^2 = 5 + 2 \sqrt{6}.
		\end{equation*}
		Therefore 
		\begin{equation*}
			24 = [(\sqrt{2}+ \sqrt{3})^2 - 5]^2 = (\sqrt{2} + \sqrt{3})^4 - 10(\sqrt{2} +
			\sqrt{3})^2 + 25.
		\end{equation*}
		Thus we have found that \( \sqrt{2} + \sqrt{3} \) is a root of \( p(x) = x^4 - 10 x^2 +1 \).
		The only possible rational roots of this polynomial are 1 and \( -1 \), and it is
		easily checked that they are not. However this does not prove that \( p(x) \) is
		irreducible, since its degree is higher than 3. However this is a biquadratic
		polynomial (a polynomial that is quadratic in \( x^2 \)), meaning its real roots can
		be computed, and so it can be factored over \( \R \). With this factorisation, one
		would	compute all four possible degree 2 factors of \( p(x) \) and find that none of
		them are rational, thus concluding that \( p(x) \) is irreducible over the rationals
		---if \( p(x) \) factored as the product of a degree 3 and a degree 1 polynomial it
		would have a rational root, which is not the case, so it can only factor as two degree
		2 polynomials---. All of this means that
		\begin{equation*}
			\ext{\Q}{\sqrt{2}+ \sqrt{3}} = 4.
		\end{equation*}
	\end{points}
\end{example}

\subsection{The Tower Formula}
One of the fundamental ideas in Galois Theory is to study field extensions in relation to other
extensions, in a setup that is called a \emph{tower of extensions} or \emph{tower of
fields}.

\begin{definition}[Tower of extensions]
	A \emph{tower of fields} is a sequence of extensions
	\begin{equation*}
		K_0 \subseteq K_1 \subseteq \cdots \subseteq K_n.
	\end{equation*}
\end{definition}

\begin{theorem}[Tower Formula] \label{theo:tower formula}
	For a tower \( K \subseteq F \subseteq \) it is true that
	\begin{equation*}
		\exte{E}{K} = \exte{E}{F} \exte{F}{K}.
	\end{equation*}
\end{theorem}
\begin{proof}
	If \( \exte{F}{K} \) is infinite then so is \( \exte{E}{K} \) since \( E \) contains \(
	F\) which is, as a \( K \)-vector space, infinite dimensional, then so mut be \( E \).
	Similarly, if \( \exte{E}{F} \) then \( E \) is infinite dimensional as a \( F \)-vector
	space which means it could not possibly be finite dimensional as a \( K \)-vector space.
	Certainly, if it were there would exist a finite \( K \)-basis for \( E \), which would
	serve as a finite \( F \)-basis, a contradiction. Thus, let's now focus on the case were
	all degrees are finite.

	Say \( \exte{E}{F} = n \) and \( \exte{F}{K} = m \). This means there exists an \( F
	\)-basis of \( E \), \( e_1, \dots, e_n \) and a \( K \)-basis of \( F \), \( f_1,
	\dots, f_m \). We will show that the vectors \( e_if_j \) with \( 1 \leq i \leq n \) and
	\( 1 \leq j \leq m \) are a \( K \)-basis of \( E \) therefore proving
	\begin{equation*}
		\exte{E}{K} = nm = \exte{E}{F} \exte{F}{K}
	\end{equation*}
	
	Expand any \( e \in E \) in the \( e_i \) basis,
	\begin{equation*}
		e = \sum_{i = 1}^{n} \lambda_i e_i 
	\end{equation*}
	Since the \( \lambda_i \in F \) we expand them in the \( f_j \) basis:
	\begin{equation*}
		e = \sum_{i = 1}^{n} \left(\sum_{j = 1}^{m} \mu_{ij} f_j\right)  e_i = \sum_{i =
		1}^{n} \sum_{j = 1}^{m} \mu_{ij} f_j  e_i
	\end{equation*}
	therefore \( E \) is spanned by the \( e_if_j \) as a \( K \)-vector space.	

	Let's now show that the \( e_if_j \) are linearly independent. We need to show that if
	there exist \( \mu_{ij}\in K \) such that
	\begin{equation*}
		\sum_{i =	1}^{n} \sum_{j = 1}^{m} \mu_{ij} f_j  e_i = 0
	\end{equation*}
	then it must be the case that all of the \( \mu_{ij} \) are zero. Let \( \lambda_i =
	\sum_{j = 1}^{m}\mu_{ij}f_j \in F  \). Then we have
	\begin{equation*}
		\sum_{i = 1}^{n}\lambda_i e_i = 0 
	\end{equation*}
	which implies, by the linear independence of the \( e_i \) over \( F \), that \(
	\lambda_i = 0 \) for	\( 1 \leq i \leq n \). And if \( \lambda_i = \sum_{j =
	1}^{m}\mu_{ij}f_j = 0  \), then	by the lienar independence of the \( f_j \) over \( K \)
	it follows that \( \mu_{ij} = 0 \) for all \( 1 \leq i \leq n \) and \( 1 \leq j \leq m
	\), as we wanted.
\end{proof}
\begin{corollary}
	For a tower \( K_0 \subseteq K_1 \subseteq \dots \subseteq K_n \) one has
	\begin{equation*}
		\exte{K_n}{K_0} = \exte{K_n}{K_{n-1}} \cdots \exte{K_1}{K_0}.
	\end{equation*}
\end{corollary}
\begin{proof}
	Simply apply the \nameref{theo:tower formula} and induction.
\end{proof}

\parbreak

The following result, which is an immediate consequence of the \nameref{theo:tower
formula}, clarifies the relationship between finite and algebraic extensions.
\begin{proposition}\label{prop:finite extensions are algebraic}
	Every finite extension is algebraic.
\end{proposition}
\begin{proof}
	Consider an extension \( K \subseteq F \). We wish to show that this extension is
	algebraic, which amounts to proving that every element of \( F \) is algebraic. For any
	\( \alpha \in F \) we have the tower \( K \subseteq K(\alpha) F \), and applying the
	\nameref{theo:tower formula} we find
	\begin{equation*}
		\exte{F}{K} = \exte{F}{K(\alpha)} \ext{K}{\alpha}.
	\end{equation*}
	Now, \( \exte{F}{F} \) is finite by hypothesis, which means \( \ext{K}{\alpha} \) must
	also be finite. By \cref{prop:degree of a simple extension}, it follows \( \alpha \) is
	algebraic.
\end{proof}
\begin{corollary}
	No transcendental extension is finite.
\end{corollary}
\begin{proof}
	This is just the contrapositive of the previous proposition.
\end{proof}
Note, however, that the converse of \cref{prop:finite extensions are algebraic} is not
true. There exist algebraic extensions which are not finite. For example, the algebraic
closure of the rationals is, by construction, algebraic but it can be shown it is not
finite.

We can, however, give a weaker converse to the previous result.
{\def\currentprefix{prop:characterisation of finite extensions}
\begin{proposition}\label{prop:characterisation of finite extensions}
	For an extension \( F \subseteq K \) it is equivalent
	\begin{points}
	\item \locallabel{i} the extension is finite,
	\item \locallabel{ii} \( F = K(\alpha_1, \dots, \alpha_n) \) where the \( \alpha_i \)
		are algebraic over \( K \),
	\item \locallabel{iii} \( F = K(\alpha_1, \dots, \alpha_n) \) where each \( \alpha_i \)
		is algebraic over \( K(\alpha_1, \dots, \alpha_{i-1}) \).
	\end{points}
\end{proposition}
\begin{proof}
	Let's show \localref{i}\( \implies \)\localref{ii}. If \( F = K \) then \( F =
	K(\emptyset) \) and we are done. Let's assume, then, that \( K \subset F \). This means
	there exist \( \alpha_1 \in F-K \). Then we have the tower 
	\begin{equation*}
		K \subset K(\alpha_1) \subseteq F
	\end{equation*}
	If it happens that \( F = K(\alpha_1) \) we are done. If not, we do the same thing, find
	\( \alpha_2 \in F - K(\alpha_1) \) and construct the tower
	\begin{equation*}
		K \subset K(\alpha_1) \subset K(\alpha_2, \alpha_1) \subseteq F.
	\end{equation*}
	This process must end at some point. Ideed, at step \( n \) we have the tower
	\begin{equation}\locallabel{eq:tower}
		K \subset K(\alpha_1) \subset K(\alpha_2, \alpha_1) \subset \cdots \subset K(\alpha_1,
		\dots, \alpha_n) \subseteq F.
	\end{equation}
	Therefore, by the \nameref{theo:tower formula}
	\begin{equation}\locallabel{eq:degrees}
		\exte{F}{K} = \exte{F}{K(\alpha_1, \dots, \alpha_n)} \cdots \ext{K}{\alpha_1}
	\end{equation}
	and every factor is strictly greater than 1 by construction. Thus we must be finished in at
	most \( \exte{F}{K} \) steps. Additionally, by \Cref{prop:finite extensions are
	algebraic} \( F \) is algebraic over \( K \), meaning every one of the \( \alpha_i \) is
	algebraic over \( K \).
	
	We now show \localref{ii}\( \implies \)\localref{iii}. If \( \alpha_i \) is algebraic
	over \( K \) then it is also algebraic over \( K(\alpha_1, \dots, \alpha_{i-1}) \).
	Indeed, \( \alpha_i \) is a root of a polynomial with coeficients in \( K \), which are
	in particular also in	\( K(\alpha_1, \dots, \alpha_{i-1}) \) thus \( \alpha_i \) is also
	algebraic over \( K(\alpha_1, \dots, \alpha_{i-1}) \).

	Lastly we prove \localref{iii}\( \implies \)\localref{i}. Construct the tower in
	\localcref{eq:tower} which gives us \localcref{eq:degrees}. By hypothesis, every
	extension
	\begin{equation*}
 		K(\alpha_1, \dots, \alpha_{i-1}) \subseteq K(\alpha_1, \dots, \alpha_{i-1})(\alpha_i) = K(\alpha_1, \dots, \alpha_{i-1}, \alpha_i)
	\end{equation*}
	is algebraic, therefore finite. This means every factor in \localcref{eq:degrees} is
	finite, therefore	\( \exte{F}{K} \) is finite as well, as we wanted.
\end{proof}
}
\parbreak

With \nameref{theo:tower formula}, together with \Cref{prop:degree of a simple extension}
and \Cref{prop:characterisation of finite extensions} we can now, in principle, compute
the degree of any finite extension. Indeed, we just showed that any finite extension is a
tower of simple algebraic extensions. We can calculate the degree of each step with
\Cref{prop:degree of a simple extension} and then put them together with
\nameref{theo:tower formula}. 

Thus the calculation reduces to the computation of the degree of simple
extensions\footnote{Of course, we are glossing over the problem of determining the
primitive elements of the extension.}, i.e. finding the minimal polynomial of a number.
This is entirely dependent on the field we are working over. In \( \C \) it is trivial by
virtue of the Fundamental Theorem of Algebra. Over \( \R \) we know that irreducible
polynomials can only be of degree 1 or 2, and we have an explicit way of determining
whether or not a certain degree 2 polynomial is irreducible. Over \( \Q \) there exist
irreducible polynomials of any degree so the task becomes harder. On the flipside we have
a number of useful tools, such as Eisenstein's criterion, the modular criterion or
Gau\ss's lemma. As we climb the tower the fields can become more exotic. The following example illustrates these ideas.
\begin{example}
	Let's calculate \( \ext{\Q}{\sqrt{p}, \sqrt{q}} \) where \( p \) and \( q \) are
	different primes.	We will make use of the tower
	\begin{equation*}
		\Q \subseteq \Q(\sqrt{q}) \subseteq \Q(\sqrt{p}, \sqrt{q}) = \Q(\sqrt{q})(\sqrt{p}).
	\end{equation*}
	Thus, by the \nameref{theo:tower formula}
	\begin{equation*}
		\exte{\Q(\sqrt{p}, \sqrt{q})}{\Q} = \ext{\Q(\sqrt{q})}{\sqrt{p}} \ext{\Q}{\sqrt{q}}.
	\end{equation*}
	We can easily see that \( \ext{\Q}{\sqrt{q}} = 2 \) since
	\begin{equation*}
		\irr{\sqrt{q}}{\Q} = x^2 - q.
	\end{equation*}

	To determine \( \ext{\Q(\sqrt{q})}{\sqrt{p}} \) we need to find \(
	\irr{\sqrt{p}}{\Q(\sqrt{q})} \), which we will simply write as \( r(x) \) for brevity's
	sake. It is not immediately clear that \( r(x) \) should equal \( x^2 -
	p\), however it does. Indeed, we have that \( \sqrt{p} \) is a root of \( x^2 - p \in
	\Q[x] \subseteq \Q(\sqrt{q})[x] \). Thus, by \Cref{prop:characterisation of the minimal
	polynomial} \( x^2 - p \) must be divisible by \( r(x) \). Therefore \( r(x) \) must be
	of degree either 1 or 2. If it were of degree 1 it would have to be \( x - \sqrt{p} \),
	since it is the only monic linear polynomial that has \( \sqrt{p} \) as a root. This
	would mean, however, that \( \sqrt{p} \in \Q(\sqrt{q}) \) given that \( r(x) \) is,
	by definition, a polynomial with coefficients in the field \( \Q(\sqrt{q}) \). Therefore
	there would exist \( a, b \in \Q \) such that
	\begin{equation}\label{eq:sqrt(p) in Q(sqrt(q))}
		\sqrt{p} = a + b\sqrt{q}.
	\end{equation}
	Squaring \cref{eq:sqrt(p) in Q(sqrt(q))} we find
	\begin{equation*}
		p = a^2 + b^2q + 2ab\sqrt{q}.
	\end{equation*}
	Since \( \sqrt{q} \neq 0 \) this forces \( ab = 0 \), or otherwise we would deduce \(
	\sqrt{q} \in \Q \), which we know is not the case. If \( b = 0 \) then we would find \(
	p = a^2 \), which cannot be true since no prime is a square in \( \Q \). And if \( a = 0
	\) we would have \( p = b^2q \) which is not possible either, by similar reasons.

	We conclude,  therefore, that \( a \) and \( b \) cannot exist and so \( \sqrt{p} \notin
	\Q(\sqrt{q}) \), or equivalently, \( r(x) \) must have degree 2. Therefore \( r(x) = x^2
	+ p \) and \( \ext{\Q(\sqrt{q})}{\sqrt{p}} = 2 \). Finally we obtain the result we set
	out to calculate
	\begin{equation*}
		\exte{\Q(\sqrt{p}, \sqrt{q})}{\Q} = 2 \cdot 2 = 4.
	\end{equation*}
\end{example}

\section{Morphisms of Field Extensions}
Another recurring question in Galois theory is the extension of a morphism on a field to a
morphism on an extension of said field. We will in general not be interested on any
morphism, but rather on morphisms which preserve the base field. This is because what we
are actually thinking about are maps between extensions. So, if we have two extensions of
the same field, \( K \subseteq F_1 \) and \( K \subseteq F_2 \) really what we want is a
map between \( F_1 \)	and \( F_2 \) which preserves the structure relevant to the
extension, so a morphism \( f \colon F_1 \to F_2 \) which makes the following diagram
commute
\begin{equation*}
	\begin{tikzcd}[column sep=small]
		F_1 \arrow[rr, "f"] & & F_2	\\
											& K \arrow[ul, hook] \arrow[ur, hook] &
	\end{tikzcd}
\end{equation*}
If \( K \) is an honest to goodness subfield of \( F \) this means that the restriction of
\( f \) to \( K \), \( f\rest{K} \) must be the identity on \( K \) since the composition
\( f \circ \iota \) is precisely \( f \rest{K} \). This means, among other things, that
this sort of morphisms, which we will call \emph{\( K \)-morphisms}, play nice with
polynomials of \( K[x] \) since they preserve their coefficients. Notice as well that a \(
K \)-morphism is linear, meaning the map \( f \colon F_1 \to F_2 \) is linear when
thinking of \( F_1 \) and \( F_2 \) as \( K \)-vector spaces. The converse, however, is
not true: a linear map from \( F_1 \) to \( F_2 \) need not be a \( K \)-morphism.

More generally, given two extensions \( K_1 \subseteq F_1 \) and \( K_2 \subseteq F_2 \)
then we define an extension morphism between the two to be a pair of morphisms \( f \colon K_1
\to K_2	\) and \( g \colon F_1 \to F_2 \) such that the following square commutes
\begin{equation*}
	\begin{tikzcd}
		F_1 \arrow[r, "g"] & F_2 \\
		K_1 \arrow[r, "f"] \arrow[u, hook] & K_2 \arrow[u, hook]
	\end{tikzcd}
\end{equation*}

It is easy to see that the composition of two extension morphisms is also an extension
morphism and that they compose associatively. In addition, the identity is always an
extension morphisms. What this means is that field extensions form a category.

\parbreak

We will mainly deal with \( K \)-automorphisms of an extension \( K \subseteq F \), that
is, automorphisms \( \sigma \colon F \to F \) that fix \( K \). These form a group (check
it!) which plays a central role in Galois theory, the \emph{Galois group} of the
extension, typically denoted \( \Gal_K(F) \). For a finite extension, if \( \sigma \)
is a \( K \)-endomorphism it is automatically a \( K \)-automorphism. Indeed, if the
extension \( K \subseteq F \) is finite then \( F \) has finite dimension as a \( K
\)-vector space. \( \sigma \) is a nonzero field morphism since it fixes \( K \), so it
must be injective. We have then an injective linear endomorphism of a finite dimensional
vector space, which implies it is actually a linear automorphism and therefore bijective.

\section{The Morphism Extension Lemmas}
We now turn to the question of the existence and uniqueness of morphisms between
extensions. We start with a simple enough result
\begin{proposition}\label{prop:K-morphisms send roots to roots}
	Let \( K \subseteq F_1 \) and \( K \subset F_2 \) be extensions and \( \sigma \colon
	F_1 \to F_2 \) a \( K	\)-morphism between them. Then, if \( \alpha \in F_1 \) is a
	root of a polynomial \( p(x) \in K[x]	\) so is \( \sigma(\alpha) \in F_2 \). 
\end{proposition}
\begin{proof}
	Let \( p(x) = \sum_{k = 0}^{n} a_k x^k  \) with \( a_k \in K \). Then, since \( \alpha
	\) is a root of \( p(x) \)
	\begin{equation*}
		0 = p(\alpha) = \sum_{k = 0}^{n} a_k \alpha^k.
	\end{equation*}
	Applying \( \sigma \) we find
	\begin{align*}
		0 & = \sigma(0) = \sigma(p(\alpha)) = \sigma\left(\sum_{k = 0}^{n} a_k \alpha^k\right)
		\\
			& = \sum_{k = 0}^{n} \sigma(a_k) \sigma(\alpha)^k
			= \sum_{k = 0}^{n} a_k \sigma(\alpha)^k \tag*{since \( \sigma \) fixes \( K \)} \\
			& = p(\sigma(\alpha))
	\end{align*}
	so \( \sigma(\alpha) \) is a root of \( p(x) \).	
\end{proof}
A special case of this proposition is the well known fact that if a polynomial with real
coefficients has a complex root it also has its complex conjugate. This is because complex
conjugation is an \( \R \)-automorphism of \( \C \).

\begin{corollary}
	\( K \)-morphisms preserve minimal polynomials.
\end{corollary}
\begin{proof}
	Let \( F_1 \) and \( F_2 \) be extensions of a field \( K \) and \( f \colon F_1 \to F_2
	\) a \( K \)-morphism between them. Suppose \( \alpha \in F_1 \) is algebraic with
	minimal polynomial \( \irr{\alpha}{K} \). By \Cref{prop:K-morphisms send roots to roots}
	\( f(\alpha) \) is also a root of \( \irr{\alpha}{K} \). Additionally \( \irr{\alpha}{K}
	\) is irreducible, so it follows
	\begin{equation*}
		\irr{\alpha}{K} = \irr{f(\alpha)}{K}.	
	\end{equation*}
\end{proof}

\parbreak

We now establish the existence and uniqueness of \( K \)-morphisms from a simple
algebraic extension \( K \) to another extension \( K \subseteq F \). Note that any such
\( K \)-morphism is solely determined by the image of a primitive element of the
extension. Indeed, we know that a simple extension of degree \( n \), \( K(\alpha) \), has
\( 1, \alpha, \dots, \alpha^{n-1} \) as a basis. Thus we would have to specify the image
of each of these elements. However, since a \( K \)-morphism is also a field morphism, it
preserves 1 and once we know the image of \( \alpha \) we know the image of all its
powers. That is to say, if we have a \( K \)-morphism from \( K(\alpha) \) to another
extension it is sufficient to know where it sends \( \alpha \). 
\begin{lemma}[Morphism Extension Lemma I]\label{lemma:morphism extension I}
	Let \( K \) be a field, \( K(\alpha) \) a simple algebraic extension of \( K \) and
	\( F \) another extension of \( K \). Then for any \( \beta \in F \) there exists a
	unique \( K	\)-morphism \( f \colon K(\alpha) \to F \) such that \( f(\alpha) = \beta \)
	if an only if \( \beta \) is a root of \( \irr{\alpha}{K} \).
\end{lemma}
\begin{proof}
	\( (\implies) \) Suppose there exists one such \( f \colon K(\alpha) \to F \) such
	that \( f(\alpha) = \beta \). We have that \( \alpha \) is a root of its minimal
	polynomial. Thus, by \Cref{prop:K-morphisms send roots to roots} we have that \( \beta =
	f(\alpha) \) must also be a root of the minimal polynomial of \( \alpha \).

	\( (\impliedby) \) Consider the evaluation at \( \beta \) morphism, \( \ev{\beta} \colon
	K[x] \to F_2 \). By hypothesis \( \beta \) is a root of \( \irr{\alpha}{K} \) thus
	\begin{equation*}
		\gen{\irr{\alpha}{K}} \subseteq \ker(\ev{\beta}).
	\end{equation*}
	But since \( \irr{\alpha}{K} \) is irreducible and \( \ev{\beta} \) is not the zero map it
	follows that we have equality,
	\begin{equation*}
		\gen{\irr{\alpha}{K}} = \ker(\ev{\beta}).
	\end{equation*}
	Thus, by the Isomorphism Theorem
	\begin{equation*}
		K(\beta) = \im(\ev{\beta}) \cong K[x]/\gen{\irr{\alpha}{K}} \cong K(\alpha)
	\end{equation*}
	which means we have an isomorphism between \( K(\alpha) \) and \( K(\beta) \). Let's try
	to determine this isomorphism explicitly. In general, given a morphism	\( f \colon A
	\to B \), the Isomorphism Theorem shows there is an induced isomorphism \( \bar{f}
	\colon A/\ker{f} \to \im{f} \) given by \( \bar{f}(\bar{a}) = f(a) \), where \( \bar{a}
	\) is the equivalence class of \( a \in A \) in \( A / \ker{f} \).
	
	Thus, we have the isomorphism 
	\begin{equation*}
		\overline{\ev{\beta}} \colon K[x]/\gen{\irr{\alpha}{K}} \to K(\beta)
	\end{equation*}
	specified by \( \overline{\ev{\beta}}(\bar{x}) = \beta \). It is easy to see that it is
	a \( K \)-morphism. By the same token, \( \overline{\ev{\alpha}} \colon
	K[x]/\gen{\irr{\alpha}{K}} \to K(\alpha) \) is also a \( K \)-morphism.

	Therefore \( \overline{\ev{\beta}} \circ \overline{\ev{\beta}}^{-1} \colon K(\alpha) \to
	K(\beta) \) is a \( K \)-isomorphism from \( K(\alpha) \) to \( K(\beta) \) which simply
	sends \( \alpha \) to \( \beta \). This should be no surprise at all, since we argued
	before that if a \( K \)-morphism between \( K(\alpha) \) and \( K(\beta) \) which sends
	\( \alpha \) to \( \beta \) were to exist then it can only possibly be what you expect:
	send \( \alpha \) to \( \beta \) and extend to \( K(\alpha) \) in the only possible
	manner. The real substance of what we have shown is that this morphism actually
	\emph{exists} when \( \alpha \) and \( \beta \) are roots of the same irreducible
	polynomial over \( K \).

	Finally, precompose with the natural inclusion	\( \iota \colon K(\beta) \into F \) to
	obtain a \( K \)-morphism from \( K(\alpha) \) to \( F \).
\end{proof}

\parbreak

Given a field morphism \( f \colon K_1 \to K_2 \) we can lift it to a ring morphism
between the corresponding polynomial rings, \( K_1[x] \) and \( K_2[x] \) by acting on the
coefficients with \( f \) and sending \( x \) to \( x \). We will write this lift as \(
\hat{f} \colon K_1[x] \to K_2[x] \). With this we can give a generalisation version of
\Cref{lemma:morphism extension I}.
\begin{lemma}[Morphism Extension Lemma II]\label{lemma:extension lemma II}
	Let \( K \) be a field and \( K(\alpha) \) a simple algebraic extension of \( K \). Then
	for any field morphism \( f \colon K \to F \) and \( \beta \in F \) there is a unique
	morphism \( \tilde{f} \colon K(\alpha) \to F \) such that \( \tilde{f}(\alpha) = \beta
	\) and which makes the following diagram commute
	\begin{equation*}
		\begin{tikzcd}
			K(\alpha) \arrow[r, dashed, "\tilde{f}"] & F \\
			K \arrow[u, hook] \arrow[ru, "f"] & 
		\end{tikzcd}
	\end{equation*}
	if and only if \( \beta \) is a root of \( \hat{f}(\irr{\alpha}{K}) \).
\end{lemma}
\begin{proof}
	\( (\implies) \) For the forward implication, suppose \( \tilde{f} \colon K(\alpha) \to
	F \) exists. Say
	\begin{equation*}
		\irr{\alpha}{K} = \sum_{k = 0}^{n} a_k x^k
	\end{equation*}
	then	
	\begin{equation*}
		(\ev{\beta} \circ \hat{f})(\irr{\alpha}{K})= \sum_{k = 0}^{n} f(a_k) \beta^k = \sum_{k
		= 0}^{n} \tilde{f}(a_k) \tilde{f}(\alpha) = \tilde{f} \left(\sum_{k = 0}^{n} a_k
		\alpha^k\right) = \tilde{f}(0) = 0.
	\end{equation*}
	So \( \beta \) is a root of \( \hat{f}(\irr{\alpha}{K}) \), as we wanted.

	\( (\impliedby) \) The argument is basically the same as the proof of
	\Cref{lemma:morphism extension I}. However, rather than directly using \( \ev{\beta}
	\) we will first apply \( \hat{f} \) to get a ``pseudoevaluation morphism'', \( \phi_\beta =
	\ev{\beta} \circ \hat{f} \). Since, by hypothesis, \( \beta \) is a root of \(
	\hat{f}(\irr{\alpha}{K} \) we have
	\begin{equation*}
		\gen{\irr{\alpha}{K}} \subseteq \ker(\phi_\beta)
	\end{equation*}
	and by the irreducibility of \( \irr{\alpha}{K} \) we actually have equality. We have
	the situation
	\begin{equation*}
		K(\alpha) \cong K[x]/\gen{\irr{\alpha}{K}} \cong \im(\phi_\beta)
	\end{equation*}
	where the explicit isomorphisms are \( \overline{\ev{\alpha}}^{-1} \) and \(
	\overline{\phi_\beta} \). 

	Let's show that \( \im(\phi_\beta) = f(K)(\beta) \subseteq F \). By hypothesis, \( \beta
	\) is algebraic over \( f(K) \) since it is a root of \( \hat{f}(\irr{\alpha}{K}) \in
	f(K)[x] \). Therefore 
	\begin{equation*}
		f(K)(\beta) = \ev{\beta}(f(K)[x]) = \ev{\beta}(\hat{f}(K[x])) = \phi_\beta(K[x]) =
		\im(\phi_\beta).
	\end{equation*}
	Additionally, the following diagram commutes
	\begin{equation*}
		\begin{tikzcd}
			K[x]/\gen{\irr{\alpha}{K}} \arrow[r, "\overline{\phi_\beta}"] & f(K)(\beta) \\
			K \arrow[u, hook] \arrow[ru, "f"] & 
		\end{tikzcd}
	\end{equation*}
	Indeed, if \( \lambda \in K \) then \( f(\lambda) \in f(K) \subseteq f(K)(\beta) \). On
	the other hand, we identify \( \lambda \) with its equivalence class in \(
	K[x]/\gen{\irr{\alpha}{K}} \), thus
	\begin{equation*}
		\overline{}(\bar{\lambda}) = \phi_\beta(\lambda) = (\ev{\beta} \circ
		f)(\lambda) = f(\lambda).
	\end{equation*}
	From this we build the diagram
	\begin{equation*}
		\begin{tikzcd}
			K(\alpha) \arrow[r, "\overline{\ev{\alpha}}^{-1}"] & K[x]/\gen{\irr{\alpha}{K}}
			\arrow[r, "\overline{\phi_\beta}"] & f(K)(\beta) \\
																				 & K \arrow[ul, hook] \arrow[u, hook] \arrow[ru,
			"f"] & 
		\end{tikzcd}
	\end{equation*}
	Thus we get an isomorphism from \( K(\alpha) \) to \( f(K)(\beta) \), which can be
	extended to \( F \). 

	The uniqueness comes from the fact that a morphism from \( K(\alpha) \) is completely
	determined by where it sends \( \alpha \), in this case to \( \beta \).
\end{proof}



\chapter{The Galois Group of an Extension}
\section{Definition}
% TODO: Expand
Galois Theory has two main ingredients. One of them are field extensions, which we
discussed in the previous chapter. The other are their Galois groups. It turns out there
is a correspondence between field extensions and their Galois groups. 

\begin{definition}[Galois Group of an Extension]
	The \emph{Galois group} of a field extension \( K \subseteq F \) is the group of \( K
	\)-automorphisms of \( F \), i.e. the group of field automorphisms of \( F \) which fix
\( K \). We write it \( \Gal_K(F) \).
\end{definition}

\begin{example}
	Let's calculate the Galois group of the field \( \Q(\sqrt{2}) \). If \( \sigma
	\in \Gal_K(F) \) then, by definition, \( \sigma \) makes the following diagram commute,
	\begin{equation*}
		\begin{tikzcd}
			\Q(\sqrt{2}) \arrow[r, "\sigma"] & \Q(\sqrt{2}) \\
			\Q \arrow[u, hook] \arrow[ur, hook] &
		\end{tikzcd}.
	\end{equation*}
	Conversely, if \( \sigma \) is a \( K \)-morphism such that the previous diagram then,
	as we have argued before, it is actually a \( K \)-automorphism and thus \( \sigma \in
	\GalQ(\Q(\sqrt{2})) \). There are, then, only two possibilities for \( \sigma \), since, by
	\Cref{lemma:morphism extension I}, it must send \( \sqrt{2} \) to one of the two
	roots of \( \irre{\sqrt{2}} = x^2 - 2 \), which are \( \sqrt{2} \) and \( -\sqrt{2} \).
	The first possibility means \( \sigma \) is in fact the identity, and the second one is
	akin to complex conjugation. This means \( \abs{\GalQ(\Q(\sqrt{2}))} = 2 \). Therefore
	\begin{equation*}
		\GalQ(\Q(\sqrt{2})) \cong \Z/2\Z.
	\end{equation*}
\end{example}

\begin{example}
	We will compute the Galois group of the field \( \Q(\xi) \) where \( \xi \) is a \( p
	\)-th root of unity different from 1 and \( p \) a prime. For the sake of concreteness,
	say
	\begin{equation*}
		\xi = e^{\frac{2\pi i}{p}}.
	\end{equation*}
	We need to determine the minimal polynomial of \( \xi \) over \( \Q \). For one, \( \xi
	\) is a root of \( x^p -1 \), but this is not irreducible. Indeed, since \( 1 \) is also
	a root, we have the factorisation
	\begin{equation*}
		x^p - 1 = (x - 1)(x^{p-1} + x^{p-2} + \cdots + 1).
	\end{equation*}
	The polynomial \( x^{p-1} + \cdots + 1 \), which is known as a cyclotomic polynomial, is
	irreducible. One uses a standard trick to show it. In the fraction field, \( \Q(x) \) we
	have
	\begin{equation*}
		x^{p-1} + \cdots + 1 = \frac{x^p - 1}{x - 1}.
	\end{equation*}
	Now aply the change of variable \( x = y + 1 \):
	\begin{equation*}
		\frac{x^p - 1}{x - 1} = \frac{(y + 1)^p - 1}{y} = \left(\frac{1}{y}\sum_{k = 0}^{p}
		\binom{p}{k}y^k\right) - \frac{1}{y} = \sum_{k = 1}^{p}\binom{p}{k}y^{k-1}.
	\end{equation*}
	The leading term of this polynomial is \( y^{p-1} \) while its last term is \( p \).
	Every other term is divisible by \( p \). We apply Eisenstein's Criterion and readily
	conclude that it is irreducible (note the importance of \( p \) being prime). A change
	of variables, as we discussed, can be thought of as an automorphism of \( \Q[x] \)
	meaning our original polynomial is also irreducible.

	All this goes to show that
	\begin{equation*}
		\irr{\xi}{\Q} = x^{p-1} + \cdots + 1.
	\end{equation*}
	This means \( \ext{\Q}{\xi} = p-1 \).  As we argued in the previous example, the
	elements of \( \Gal_\Q(\Q(\xi)) \) are in bijection with the roots of \( \irr{\xi}{\Q}
	\) in \( \Q(\xi) \). It is easy to check that its roots are every power of \( \xi \),
	except for 1, of which there are \( p-1 \). Thus, we have \( p-1 \) elements in	\(
	\GalQ(\Q(\xi)) \), given by
	\begin{equation*}
		\sigma_i(\xi) = x^i.
	\end{equation*}
	Consider the map
	\begin{align*}
		\Phi \colon \F_p^{\times} & \to \GalQ(\Q(\xi)) \\
		i & \mapsto \sigma_i
	\end{align*}
	where \( \F_p \) is the finite field of order \( p \) and \( \F_p^{\ast} \) its
	multiplicative group. \( \Phi \) is surjective and since its domain and codomain have
	the same number of elements, it is bijective. It is also a group homomorphism since
	\begin{equation*}
		\Phi(i_1 i_2)(\xi) = f_{i_1i_2}(\xi) = \xi^{i_1 i_2} = (\xi^{i_1})^{i_2} = (f_{i_1}
		\circ f_{i_2})(\xi) = (\Phi(i_1)\circ\Phi(i_2))(\xi).
	\end{equation*}
	So it follows that \( \GalQ(\Q(\xi)) \cong \F_p^{\times} \), and, by the Primitive
	Element Theorem, \( \F_p^{\times} \) is cyclic of order \( p-1 \). 
	
 	More generally, for the extension generated by the \( n \)-th roots of unity, where \( n
 	\) may or may not be a prime, one has the result
 	\begin{equation*}
 		\GalQ(\Q(\xi)) \cong \Z/n\Z^{\times}
 	\end{equation*}
 	



\end{example}

\section{Galois Groups of Finite Extensions}



\section{The Discriminant}
There is a quantity that is very useful in the calculation of Galois groups of
polynomials, known as the \emph{discirminant}. It is a generalisation of the quadratic
disriminant, \( b^2 - 4ac \), which, hence its name, discriminates between different
situtations for the existence of roots of the polynomial.

\begin{definition}[Discriminant]
	The \emph{discriminant} of a polynomial \( p(x) \in K[x] \) with roots \( \alpha_1,
	\dots,\alpha_n \) in its splitting field is
	\begin{equation*}
		\Delta(p(x)) = \prod_{i < j}(\alpha_i - \alpha_j)^2.
	\end{equation*}
	We also define the quantity
	\begin{equation*}
		\delta(p(x)) = \prod_{i < j}(\alpha_i - \alpha_j).
	\end{equation*}
\end{definition}

\chapter{Normal and Separable Extensions}
\section{Normal Extensions}
\begin{definition}[Normal Extension]
	We say a field extension \( K \subseteq F \) is \emph{normal} if it is algebraic and if every
	irreducible polynomial of \( k[x] \) which has a root in \( F \) splits in \( F \).
\end{definition}
This definition suggests a certain relationship between normal extensions and splitting
fields, since both have to do with the property of a polynomial automatically splitting if
it has a root. The following result clarifies this relationship.

\begin{theorem}
	A finite extension is normal if and only if it is the splitting field of a polynomial.
\end{theorem}
\begin{proof}
	\( (\implies) \) Suppose \( K \subseteq F \) is a finite normal extension. By
	\Cref{prop:characterisation of finite extensions}, \( F \) is of the form \( F =
	K(\alpha_1, \dots, \alpha_n) \) with \( \alpha_1, \dots, \alpha_n \in F \) algebraic
	over \( K \). We will show that \( F \) is the splitting field of
	\begin{equation*}
		p(x) = \irre{\alpha_1}\cdots\irre{\alpha_n}.
	\end{equation*}
	Every	\( \irre{\alpha_i} \) is irreducible and has a root in \( F \), namely \( \alpha_i
	\). By normality they all split in \( F \) which means \( p(x) \) splits in \( F \).
	Let's show that \( F \) is the minimal field in which \( p(x) \) splits, thus its
	splitting field. Consider an extension \( F' \) in which \( p(x) \) splits and such that
	\( K \subset F' \subset F \). Then \( F' \) contains every root of \( p(x) \), in
	particular \( \alpha_1, \dots, \alpha_n \). Thus \( F = K(\alpha_1, \dots, \alpha_n)
	\subseteq F' \), therefore \( F = F' \). Then it follwos \( F \) is the splitting field
	of \( p(x) \).

	\( (\impliedby) \) Let's now assume \( F \) is the splitting field of a polynomial \(
	q(x) \in K[x] \). Let \( p(x) \in K[x] \) be an
	irreducible polynomial with a root in \( F \). If we can show that in fact any
	root of \( p(x) \) is in \( F \) then we can conclude that \( F \) is normal. We will
	show that in fact the extension that results from adjoining a root of \( p(x) \) to \( F
	\) has the same degree no matter which root we choose. Thus, if \( p(x) \) has a root in
	\( F \) then the adjunction of that root gives an extension of degree 1. It follows that
	any other such extension has degree 1 and therefore any other root of \( p(x) \) is in
	\( F \), proving normality.

	Let \( L \supseteq K \) be the splitting field of \( p(x) \) over \( F \). Then \( L \)
	contains every	root of \( p(x) \). Let \( \alpha \) and \( \beta \) be any two of these
	roots. We can	construct the following	diagram, where every line simply represents an
	inclusion.
	\begin{equation*}
		\begin{tikzcd}[row sep=small]
		& L &  \\
			F(\alpha) \arrow[ru, dash] & & F(\beta) \arrow[lu, dash] \\
																 & F \arrow[lu, dash] \arrow[ru, dash] & \\
			K(\alpha) \arrow[uu, dash] & & K(\beta) \arrow[uu, dash] \\
																 & K \arrow[uu, dash] \arrow[ru, dash] \arrow[lu, dash] &
		\end{tikzcd}
	\end{equation*}
	We will show that \( F(\alpha) \) and \( F(\beta) \) have the same degree over \( F \),
	which means that if one of the roots of \( p(x) \) is in \( F \)
	Now, using the \nameref{theo:tower formula} we have
	\begin{equation}\label{eq:degree of F(a) one way}
		\exte{F(\alpha)}{K} = \exte{F(\alpha)}{K(\alpha)}\ext{K}{\alpha}.
	\end{equation}
	Since \( p(x) \) is irreducible over \( K \) and it has \( \alpha \) as a root it is
	actually the minimal polynomial of \( \alpha \), thus
	\begin{equation*}
		\ext{K}{\alpha} = \deg{p(x)},
	\end{equation*}
	which, when substituted in \cref{eq:degree of F(a) one way} yields \(
	\exte{F(\alpha)}{K} = \exte{F(\alpha)}{K(\alpha)}\deg{p(x)} \). By going down through \(
	F\) instead of \( K(\alpha) \) we find
	\begin{equation*}
		\exte{F(\alpha)}{K} = \ext{F}{\alpha} \exte{F}{K}.
	\end{equation*}
	Thus
	\begin{equation} \label{eq:degree of F(a) both ways}
		\ext{F}{\alpha} \exte{F}{K} = \exte{F(\alpha)}{K(\alpha)} \deg{p(x)}.
	\end{equation}
	The exact same calculations hold substituting \( \alpha \) by \( \beta \) and so we also
	have
	\begin{equation} \label{eq:degree of F(b) both ways}
		\ext{F}{\beta} \exte{F}{K} = \exte{F(\beta)}{K(\beta)} \deg{p(x)}.
	\end{equation}

	Now, since \( F \) is the splitting field of \( q(x) \) over \( K \) it follows \(
	F(\alpha) \) is a splitting field of \( q(x) \) over \( K(\alpha) \). Indeed, if \(
	q(x) \) were to split in a field inbetween, \( Q \), then \( Q \) would contain \(
	K \), \( \alpha \) and every root of \( q(x) \). Thus it would contain \( F \) and \(
	\alpha \), by virtue of \( F \) being a splitting field, which means \( F(\alpha)
	\subseteq Q \). For the same reason \( F(\beta) \) is the splitting field of \( q(x) \)
	over \( K(\beta) \). 
	
	We can show \( K(\alpha) \) and \( K(\beta) \) are isomorphic. Indeed, \(
	p(x) \) is irreducible over \( K \) and has \( \alpha \) as a root in \( K(\alpha) \)
	and \( \beta \) as a root in \( K(\beta) \). Thus, using the \nameref{lemma:morphism
	extension I} there is a \( K \)-morphism from \( K(\alpha) \) to \( K(\beta) \) which
	sends \( \alpha \) to \( \beta \), and conversely, a morphism from \( K(\beta) \) to \(
	K(\alpha)\) which sends \( \beta \) to \( \alpha \). These are, therefore, inverses of
	each other. What this means is that \( K(\alpha) \) and \( K(\beta) \) are essentially
	the same field, meaning, by the uniqueness up to isomorphism of the splitting field,
	that \( F(\alpha) \) and \( F(\beta) \) must also be isomorphic. We thus have the
	diagram
	\begin{equation*}
		\begin{tikzcd}[column sep = small]
			F(\alpha) \arrow[rr, "\sim"] & & F(\beta) \\
			K(\alpha) \arrow[rr, "\sim"] \arrow[u, hook] & &  K(\beta) \arrow[u, hook] \\
																									 & K \arrow[lu, hook] \arrow[ru, hook] &
		\end{tikzcd}
	\end{equation*}
	from which one deduces that
	\begin{equation*}
		\exte{F(\alpha)}{K(\alpha)} = \exte{F(\beta)}{K(\beta)}.
	\end{equation*}
	And from this follows
	\begin{equation*}
		\exte{F(\alpha)}{K} = \exte{F(\alpha)}{K(\alpha)} \deg{p(x)} =
		\exte{F(\beta)}{K(\beta)} \deg{p(x)} = \exte{F(\beta)}{K}.
	\end{equation*}
	Finally, combining this with \cref{eq:degree of F(a) both ways,eq:degree of F(a) both
	ways} we find
	\begin{equation*}
		\ext{F}{\alpha} = \frac{\exte{F(\alpha)}{K}}{\exte{F}{K}} =
		\frac{\exte{F(\beta)}{K}}{\exte{F}{K}} = \ext{F}{\beta}.
	\end{equation*}
	
	Thus, as we previously argued, if \( p(x) \) has a root in \( F \), say \( \alpha \)
	then we have \( \ext{F(\alpha)}{F} = 1 \) since \( F(\alpha) = F \). Therefore, for any
	other root of \( p(x) \) we have \( \ext{F}{\beta} = 1 \) which implies \( F(\beta) = F
	\) and \( \beta \in F \). Thus \( p(x) \) splits in \( F \) and we conclude \( F \) is
	normal.
\end{proof}
From this result it follows that every splitting field is a normal extension, since a
splitting field is finite. The converse, however, need note be true.
converse need not be true.

\begin{example}
	The extension \( \Q \subseteq \Q(\sqrt[3]{2}) \) is finite but it is not normal. Indeed,
	\( x^3 - 2 \) is irreducible over \( \Q \) and it has a root in \( \Q(\sqrt[3]{2}) \),
	namely \( \sqrt[3]{2} \). However, the other two roots of \( x^3 - 2 \) are not in \(
	\Q(\sqrt[3]{2}) \) since they are not real and \( \Q(\sqrt[3]{2}) \) is contained in \( \R
	\). However, if \( \omega = e^{\frac{2 \pi i}{3}} \) then \( \Q(\sqrt[3]{2}, \omega) \) is
	the splitting field of \( x^3 - 2 \). By what we have just shown it must be a normal
	extension.

	Incidentally, this example shows that if we have a normal extension \( K \subseteq F \) it
	is not in general true that an extension sandwiched inbetween, \( K \subseteq E \subseteq
	F\) is also normal over \( K \). 
\end{example}

\section{Separable Extensions}
\subsection{The Formal Derivative}
It makes no sense to speak of the derivative of a polynomial in the context of a general
polynomial ring since we don't even have a topology on this space. What we can do is
define, in purely algebraic terms, a map which mimics a number of the properties of the
derivative from Analysis, which turns out to also have useful algebraic properties. 
\begin{definition}[Formal Derivative]
	The \emph{formal derivative} or simply \emph{derivative} is the linear map \( D \colon
	K[x] \to K[x] \) defined by
	\begin{align*}
		D(1) & = 0\\
		D(x^n) & = nx^{n-1} \text{ for \( n \geq 1 \)}.
	\end{align*}
\end{definition}

The derivative has a number of familiar properties
{\def\currentprefix{prop:properties of the derivative}
\begin{proposition}\label{prop:properties of the derivative}
	Let \( K[x] \) be a polynomial ring and \( D \colon K[x] \to K[x] \) the formal
	derivative operator. Then
	\begin{points}
	\item\locallabel{i} \( D \) is linear,
	\item\locallabel{ii} \( D \) satisfies the Leibniz Product Rule, that is, for any \(
		p(x), q(x) \in K[x] \)
		\begin{equation*}
			D(p(x)q(x)) = D(p(x)) q(x) + p(x)D(q(x)).
		\end{equation*}
	\end{points}
\end{proposition}
\begin{proof}
	\localref{i} follows immediately from the definition of \( D \).

	If \( p(x) \) or \( q(x) \) are 0 then \localref{ii} is clearly true. It is also clearly
	true if \( q(x) = 1 \). Let's show it for the case \( q(x) = x^n \) with \( n \geq 1 \).
	Let \( p(x) = \sum_{k = 1}^{m}a_k x^k  \). Then
	\begin{align*}
		D(p(x)x^n) & = D\left(\sum_{k = 0}^{n} a_k x^{k + n}\right) = \sum_{k = 0}^{n} (k +
		n)a_k x^{k+n-1} \\
							 & = x^n\sum_{k = 1}^{n}ka_k x^{k - 1} + nx^{n-1}\sum_{k = 1}^{n}a_k x^k \\
							 & x^nD(p(x)) + nx^{n-1}p(x) = x^nD(p(x)) + D(x^n)p(x).
	\end{align*}
	Now, if \( q(x) = \sum_{k = 0}^{n}b_kx^k  \) we have
	\begin{align*}
		D(p(x)q(x)) & = D\left(\sum_{k = 0}^{n} p(x)a_k x^k\right) = \sum_{k = 0}^{n} a_k
		D(p(x)x^k) \\
								& = \sum_{k = 0}^{n} a_k\left(D(p(x))x^k + kp(x)x^{k-1}\right) \\
								& = D(p(x))\sum_{k = 0}^{n}a_k x^k + p(x)\sum_{k = 1}^{n} ka_kx^{k-1} \\
								& = D(p(x))q(x) + p(x)D(q(x)),
	\end{align*}
	as we wanted.
\end{proof}
}
If the field we are working over has characteristic 0 then the derivative of any
polinomial with degree greater than or equal to 1 is nonzero. On the other hand, if our
base field has finite characteristic \( p \) then \( D(x^p) = px^{p-1} = 0 \).

\subsection{GCD in Different Rings}
We will show that the GCD behaves well for PIDs.
\begin{lemma}
	Let \( R \) and \( S \) be PIDs and \( f \colon R \to S \) be an injective ring
	morphism. Then, for any \( a,b \in R \)
	\begin{equation*}
		f(\mcd{R}(a,b)) = \mcd{S}f(a), f(b)).
	\end{equation*}
\end{lemma}
\begin{proof}
	If either \( a \) or \( b \) are 0 then the result is clear. Suppose, then, \( a \) and
	\( b \) are both nonzero. Since \( f \) is injective then \( f(a) \) and \( f(b) \) are
	also both nonzero. Let \( d \) be a greatest common divisor of \( a \) and \( b \).
	Since \( R \) is a PID then this is equivalent to \( d \) being a generator of the sum
	of the ideals generated by \( a \) and \( b \):
	\begin{equation*}
		\gen{d} = \gen{a} + \gen{b}.
	\end{equation*}
	This means there exist nonzero \( r,s \in R \) such that \( d = ra + sb \). Applying \(
	f \) we	find
	\begin{equation*}
		f(d) = f(r)f(a) + f(s)f(b) 
	\end{equation*}
	where none of the terms are zero since \( f \) is injective. This means 
	\begin{equation*}
		\gen{f(d)} \subseteq \gen{f(a)} + \gen{f(b)}.
	\end{equation*}
	\( d \) is a divisor of both \( a \) and \( b \), meaning there exist \( \alpha, \beta
	\in R \) such that \( a = \alpha d \) and \( b = \beta d \). Thus \( f(a) =
	f(\alpha)f(d) \) and \( f(b) = f(\beta)f(d) \). This means \( f(d) \) divides both \(
	f(a) \) and \( f(b) \), therefore \( \gen{f(a)} + \gen{f(b)} \subseteq \gen{f(d)} \).
	Thus 
	\begin{equation*}
		\gen{f(d)} = \gen{f(a)} + \gen{f(b)}	
	\end{equation*}
	which means \( f(d) \) is a greatest common divisor of \( f(a) \) and \( f(b) \).
\end{proof}

\end{document}
