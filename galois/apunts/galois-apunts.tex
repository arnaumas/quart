\documentclass[12pt,oneside]{book}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage[bf,sf,small,pagestyles]{titlesec}
\usepackage{titling}
\usepackage[font={footnotesize, sf}, labelfont=bf]{caption} 
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{tikz-cd}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage[sort]{cleveref}
\usepackage{amsthm,thmtools}
\usepackage[shortlabels]{enumitem}

\geometry{
	a4paper,
	right = 3cm,
	left = 3cm,
	bottom = 3cm,
	top = 3cm
}
\onehalfspace

\hypersetup{
	colorlinks,
	linkcolor = {red!50!blue},
	linktoc = page
}

\numberwithin{table}{section}
\numberwithin{equation}{section}
\numberwithin{figure}{section}

\newcommand{\qedtriangle}{\ensuremath{\triangle}}
\newcommand{\qedtriangledown}{\ensuremath{\bigtriangledown}}
\declaretheoremstyle[spaceabove=6pt, spacebelow=6pt, headfont=\bfseries, notefont=\normalfont, notebraces={(}{)}, qed=\qedtriangle]{definition}
\declaretheoremstyle[spaceabove=6pt, spacebelow=6pt, headfont=\bfseries, notefont=\normalfont, notebraces={(}{)}, qed=\qedtriangledown]{example}

\declaretheorem[name=Theorem, refname={theorem,theorems}, Refname={Theorem,Theorem}, numberwithin=chapter]{theorem}
\declaretheorem[name=Proposition, refname={proposition,propositions}, Refname={Proposition,Propositions}, numberlike=theorem]{proposition}
\declaretheorem[name=Definition, style=definition, refname={definition,definitions}, Refname={Definitio,Definitions}, numberwithin=chapter]{definition}
\declaretheorem[name=Example, style=example, refname={example,examples}, Refname={Example,Examples}, numberwithin=chapter]{example}

\newlist{points}{enumerate}{1}
\setlist[points,1]{label=\textup{(}{\itshape \roman*}\textup{)}, wide, \topsep=0pt, \itemsep = \parskip}

\graphicspath{{./figs/}}
\newcommand{\dummyfig}[1]{
  \centering
  \fbox{
    \begin{minipage}[c][0.33\textheight][c]{0.5\textwidth}
      \centering{\ttfamily #1}
    \end{minipage}
  }
}

% Unitats
\sisetup{
	inter-unit-product = \ensuremath{ \cdot },
	allow-number-unit-breaks = true,
	detect-family = true,
	list-final-separator = { and },
	list-units = single
}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\rest}[1]{\raisebox{-.5ex}{$|$}_{#1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\A}{\mathcal{A}}
\renewcommand{\S}{\mathfrak{S}}
\newcommand{\into}{\hookrightarrow}
\newcommand{\id}{\mathrm{id}}
\newcommand{\ev}[1]{\mathrm{ev}_{#1}}
\newcommand{\gen}[1]{\langle #1 \rangle}
\newcommand{\parbreak}{
	\begin{center}
		--- $\ast$ ---
	\end{center} 
}
\makeatletter
\newcommand*{\defeq}{\mathrel{\rlap{%
    \raisebox{0.3ex}{$\m@th\cdot$}}%
  \raisebox{-0.3ex}{$\m@th\cdot$}}%
	=
}
\makeatother

\newpagestyle{page}[\sffamily \footnotesize]{
	\headrule
	\sethead*{\ifthesection{{\bfseries \thesection} \sectiontitle}{}}{}{{\bfseries Chapter \thechapter.} \chaptertitle}
	\footrule
	\setfoot*{}{}{\thepage}
}
\renewpagestyle{plain}[\sffamily \footnotesize]{
	\footrule
	\setfoot*{}{}{\thepage}
}
\assignpagestyle{\chapter}{plain}

\titleformat{\chapter}[block]{\sffamily \bfseries \Huge}{\filleft \large Chapter \Huge \thechapter\\}{0pt}{\Huge \titlerule[1pt] \vspace{1ex} \filleft}

\title{Galois Theory}
\author{Arnau Mas}
\date{2019}

\begin{document}
\maketitle

\frontmatter
\pagestyle{plain}
These are notes gathered during the subject \emph{Teoria de Galois} as taught by Francesc Perera between September 2019 and January 2020.

\mainmatter

\chapter{Preliminaries}
\section{The solution of low degree polynomial equations}
It is surely well-known to any aspiring mathematician that there exist no general formulas for the solutions of polynomial equations of degree five and higher. This implies, of course, that such formulas exist for equations of degree fourth and lower. Indeed, the solution of linear equations is trivial and the quadratic formula should be more than well-known by this point. In this section we present a derivation of the solutions of both the quadratic and cubic equations. 

\subsection{The quadratic equation}
First, note that we can, without loss of generality, assume that we are working with a monic equation since we may always divide through by the leading coefficient to obtain an equation with the same solutions and with leading coefficient 1. Thus, we are trying to solve \( x^2 + bx + c = 0 \). The standard method is completing the square, that is to write \( x^2 + bx + c \) as a square, and one achieves so by adding and substracting \( \frac{b^2}{4} \):
\begin{equation*}
	x^2 + bx + c = x^2 + bx + \frac{b^2}{4} - \frac{b^2}{4} + c = \left(x + \frac{b}{2}\right)^2 - \frac{b^2}{4} + c.
\end{equation*}
Then the solutions to the original equation must satisfy
\begin{equation*}
	\left(x + \frac{b}{2}\right)^2 = \frac{b^2}{4} - c.
\end{equation*}
If the term on the right is not a square in the field we are working over then there are no solutions in that field. On the other hand, if it is a square then it has two square roots and the solutions to the original equation are
\begin{equation*}
	x = - \frac{b}{2} \pm \frac{1}{2}\sqrt{b^2 - 4c},
\end{equation*}
which is the well known quadratic formula.

\subsection{The cubic equation}
Less well-known is the formula for the solutions of the cubic equation. Whereas the quadratic formula had been known to the greeks and babylonians, the cubic formula was discovered later during the fifteenth century. There were several italian mathematicians involved in its discovery: Cardano, Ferrari and del Ferro among others. The question of the original discoverer is a contemptious matter. 

The first step in the solution is a change of variables to eliminate the quadratic term. If \( x = y - \frac{1}{3}b \) then the original (monic) polynomial becomes
\begin{align*}
	x^3 + bx^2 + cx + d &= y^3 - by^2 + \frac{1}{3}b^2 y - \frac{1}{27}b^3 + by^2 - \frac{2}{3}b^2y + \frac{1}{9}b^3 + cy - \frac{1}{3}bc + d \\
											&= y^3 + \left(c - \frac{1}{3}b^2 \right)y + \frac{2}{27}b^3 - \frac{1}{3}bc + d.
\end{align*}
Therefore we only need to be able to solve cubics of the form \( x^3 + px + q = 0 \). 

The basic trick is similar to completing the square. We have the identity
\begin{equation*}
	(u+v)^3 = u^3 + 3u^2v + 3uv^2 + v^3 = u^3 + 3uv(u+v) + v^3,
\end{equation*}
and rearranging we obtain \( (u+v)^3 - 3uv(u+v) - u^3 - v^3 = 0 \). One then notices that there are cubic and linear terms in \( u+v \) but no quadratic terms. Then one tries to solve for \( u \) and \( v \) to then obtain \( x \) as \( u+v \). \( u \) and \( v \) must satisfy \( -3uv = p \) and \( -u^3 - v^3 = q \). Multiplying this second condition by \( u^3 \) we get
\begin{equation*}
	u^6 + qu^3 + u^3v^3 = 0,
\end{equation*}
and using the fact that \( uv = -\frac{1}{3}p \) we arrive at
\begin{equation*}
	u^6 + qu^3 - \frac{p^3}{27} = 0,
\end{equation*}
which is quadratic in \( u^3 \). If we instead had multiplied through by \( v^3 \) we would have arrived to the same equation for \( v^3 \) instead.

Up to now nothing we have done relied on any additional assumption on the field have been working over. From this point, however, the nature of the solutions will depend on the behaviour of radicals in the field in question. We will assume we are working in \( \C \). We can then solve for \( u^3 \) and \( v^3 \) to find
\begin{align*}
	u^3 &= -\frac{q}{2} \pm \sqrt{\frac{q^2}{4} + \frac{p^3}{27}} \\
	v^3 &= -\frac{q}{2} \pm \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}.
\end{align*}
The ambiguity with the signs is eliminated due to the fact that \( u^3 + v^3 = -q \) so we find the only good options are those in which the signs of the square root terms are opposite, so that they will cancel when added. Since we only care about the sum of \( u \) and \( v \) we might as well choose
\begin{equation*}
	u^3 = -\frac{q}{2} + \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}
\end{equation*}
and 
\begin{equation*}
	v^3 = -\frac{q}{2} - \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}.
\end{equation*}
There are three possibilities for \( u \) and three for \( v \). Indeed, every complex number has three roots and if \( a \) is one of them then so are \( \omega a \) and \( \omega^2 a \) where \( \omega = e^{\frac{2\pi}{3}i} \). Not every combination of them leads to a solution of the cubic ---if it were so we would have more than three roots and a cubic polynomial can only have three roots--- since they are constrained by the relation \( 3uv = -p \). So, once we find \( u \) and \( v \) that satisfy this then so will \( \omega u \) and \( \omega^2 v \), as well as \( \omega^2 u \) and \( \omega v \) since \( \omega^3 = 1 \).

All together, one of the solutions to the cubic \( x^3 + px + q = 0 \) is given by
\begin{equation*}
	x = \sqrt[3]{-\frac{q}{2} + \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}} + \sqrt[3]{-\frac{q}{2} - \sqrt{\frac{q^2}{4} + \frac{p^3}{27}}},
\end{equation*}
which is known as Cardano's formula. If we undo the change of variable to eliminate the quadratic term and use \( p = c - \frac{1}{3}b^2 \) and \( q = \frac{2}{27}b^3 - \frac{1}{3}bc + d \) then we obtain the cubic formula in all of its glory:
\begin{align*}
	x = -\frac{b}{3} &+ \sqrt[3]{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right) + \sqrt{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right)^2 + \left(\frac{c}{3} - \frac{b^2}{9}\right)^3}} \\
									 & +\sqrt[3]{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right) - \sqrt{\left(-\frac{b^3}{27} + \frac{bc}{6} - \frac{d}{2}\right)^2 + \left(\frac{c}{3} - \frac{b^2}{9}\right)^3}}.
\end{align*}


\section{Polynomial rings}
The study of polynomial rings is particularly important in Galois theory since they play an important role in many of the constructions and definitions of the theory. Of special relevance is the study of their quotient rings.  

\subsection{The universal property of polynomial rings}
Given a ring\footnote{We will always assume that we are dealing with commutative rings with identity unless otherwise stated.} \( R \) its polynomial ring \( R[x] \) can be defined in various ways. Most commonly, the elements of \( R[x] \) are said to be ``formal sums'' of the form
\begin{equation*}
	\sum_{k = 1}^{n} a_k x^k 
\end{equation*}
where the \( a_k \) are elements of \( R \) and \( x \) is refered to as an ``indeterminate'' or some other similarly ambiguous term. This definition may feel imprecise to the more technically inclined reader. A more exact definition of \( R[x] \) is as the set of sequences of elements of \( R \) with finite suport. The sum is defined pointwise and the product is defined in a convoluted manner which correspond to the way one would multiply polynomials with repeated application of the distribuitive law. Then there is a canonical inclusion \( R \into R[x] \) by way of \( a \mapsto (a,0, \cdots) \). And if we define \( x \) to be the sequence \( (0,1, \cdots) \) then we recover the more standard presentation of \( R[x] \).

This discussion, however, is about what a programmer would call the implementation details and it misses the bigger picture. How \( R[x] \) is constructed is not really what is relevant here. It is much more illuminating to think about what we want out of \( R[x] \) instead. For one, \( R[x] \) should contain \( R \). We could require \( R \subseteq R[x] \), but let's be more general and allow for an injective morphism \( \iota \colon R \into R[x] \) that picks out a copy of \( R \) inside \( R[x] \). The other important aspect of \( R[x] \) is the indeterminate. The way to formalize it is with what is known as a universal property: for any morphism \( \phi \colon R \to S \) and distinguished element \( s \in S \) there is a unique morphism \( \tilde{\phi} \colon R[x] \to S \) such that \( \tilde{\phi} \circ \iota = \phi \) and \( \tilde{\phi}(x) = s \). That is, \( \tilde{\phi} \) must agree with \( \phi \) on \( R \) and it must send \( x \) to \( s \). This does indeed uniquely determine \( \tilde{\phi} \). It can be shown that this determines \( R[x] \) up to unique isomorphism, meaning there is a unique isomorphism between any two rings that satisfy the universal property. So you can construct \( R[x] \) in whatever way you like so long as the result satisfies the universal property.

One last remark about polynomial rings in many variables: once we have defined the polynomial ring of a ring \( \R \), we can then proceed inductively to define the polynomial ring on \( n \) variables as \( R[x_1, \cdots, x_n] = R[x_1, \cdots, x_{n-1}][x_n] \). Polynomial rings in more than one variables also satisfy a universal property, which is essentially the same as before except now we have to specify where \( \tilde{\phi} \) sends all of the \( x_i \).

This universal property is not just of theoretical importance, it is also extermely practical. Indeed, it provides a very quick way of specifying morphisms on a polynomial ring. All you need is to specify how it acts on the coeficients and where it sends the indeterminate and you're done.

\begin{example}\label{exe:morphisms on polynomial rings}
	These are various examples of morphisms defined on a polynomial ring making use of the universal property.
	\begin{points}
	\item For any element \( \alpha \in R \) we can define the evaluation morphism \( \ev{\alpha} \colon R[x] \to R \) such that \( \ev{\alpha}\rest{R} = \id_R \) and \( \ev{\alpha}(x) = \alpha \). That is, simply evaluate a polynomial on the element \( \alpha \in R \). The element we evaluate at need not be an element of \( R \), in fact it can be an element of any ring which contains \( R \). 

	\item A trick that is often used when working with polynomials is a change of variable. This idea can be made formal in terms of an automorphism of \( R[x] \). Say we wanted to make the change \( y = x+1 \), or \( x = y-1 \). This amounts to defining a morphism \( \phi \colon R[x] \to R[x] \) such that \( \phi \rest{R} = \id_R \) and \( \phi(x) = y-1 \). \( \phi \) does not move the coeficients and changes \( x \) to \( y-1 \). More generally, we could perform a change of the form \( \phi(x) = ay + b \). In order for \( \phi \) to be an isomorphism, \( a \) must be invertible. Indeed, \( \phi^{-1} \) sends \( x \) to \( a^{-1}(x - b) \). Then, when showing that a certain polynomial is irreducible, for instance, we can do any change of variable we please and rest assured that the resulting polynomial will be irreducible if and only if the original one was irreducible, for irreducibility is preserved under isomorphism.	

	\item Any permutation \( \sigma \in \S_n \) induces an isomorphism on \( R[x, \dots, x_n] \) by permuting the variables according to \( \sigma \). Indeed, let \( \phi_{\sigma} \) be the unique morphism that is the identity on \( R \) and such that \( \phi_{\sigma}(x_i) = x_{\sigma(i)} \). You can check that \( \phi_{\sigma} \circ \phi_{\tau} = \phi_{\sigma \circ \tau} \). And as a corollary \( \phi_{\sigma}^{-1} = \phi_{\sigma^{-1}} \). This is in fact an action of the symmetric group \( \S_n \) on \( R[x_1, \cdots, x_n] \). The polynomials invariant under this action, \( R[x_1, \cdots, x_n]^{\S_n} \) are known as the \emph{symmetric polynomials}.

	\end{points}
\end{example}

\chapter{Field extensions}

\section{First definitions and examples}
\begin{definition}[Field extension]
	We say a field \( F \) is an \emph{extension} of a field \( K \) if \( K \) is a subfield of \( F \). More generally, given any field \( K \) and an injective morphism \( \iota \colon K \hookrightarrow F \) we will refer to the situation as a field extension and often identify \( K \) with \( \iota(K) \) and simply write \( K \subseteq F \). 
\end{definition}

\begin{example}
Here are various examples of field extensions.
\begin{points}
	\item We have some obvious field extensions, \( \Q \subseteq \R \) and \( \R \subseteq \C \). 
	\item The following is a standard way of constructing a field extension. Let \( K \) be a field and \( p(x) \in K[x] \) an irreducible polynomial. Then, since \( K[x] \) is a PID then the ideal generated by \( p(x) \), \( \gen{p(x)} \) is a maximal ideal. Therefore, the quotient \( F = K[x]/\gen{p(x)} \) is a field, and in fact, a field extension of \( K \). Indeed, we have an inclusion \( \iota \colon K \to K[x] \) and a projection \( \pi \colon K[x] \to F \). The composition \( \pi \circ \iota \) is an injective morphism. This is because passing to the quotient through \( \pi \) leaves \( K \) untouched since the equivalence class of an element of \( K \) modulo \( \gen{p(x)} \) is comprised exactly by the element itself.   

		We can say more about the structure of \( F \). It is in fact a \( K \)-vector space. Simply define scalar multiplication by elements of \( K \) as the product given by a field structure. This a general fact about field extensions. The dimension of \( F \) is precisely \( \deg{p(x)} \). One possible basis is \( \set{1, \bar{x}, \dots, \bar{x}^{n-1}} \). That they span \( F \) is because any terms of degree \( n \) or higher get transformed into terms of lower degree, by virtue of the fact that if \( p(x) = x + \sum_{k = 1}^{n-1}a_k x^k  \) then in \( F \)
		\begin{equation*}
			\bar{x}^n = \sum_{k = 1}^{n-1}a_k \bar{x}^k. 
		\end{equation*}

	\item Say we have a field extension \( K \subseteq F \). We have seen ()  

	\end{points}
\end{example}

\section{Simple extensions}
Simple extensions are one of the fundamental building blocks of Galois theory. In what we will give different equivalent constructions and some of their properties.

A simple extension is the result of adding a single element to a field. For example, there is no element in	\( \R \) whose square is \( -1 \). We could define a new element, call it \( i \), 
such that \( i^2 = -1 \). The field that we get as a result is of course the complex field \( \C \). An analogous example consists of adding an element to \( \Q \) whose square is 2, which we may simply denote by \( \sqrt{2} \). The resulting object is often written as \( \Q[\sqrt{2}] \).

In these two examples we are somehow plucking a new element out of thin air that satisfies a certain property and throwing it into an existing field and see what comes out. There are various ways to formalise this construction.



Say we wish to adjoin to a field \( K \) an element \( \alpha \) that satisfies some sort of polynomial equation, that is, it is the root of some polynomial \( p(x) \in K[x] \). First, if \( p(x) \) is not irreducible we may factor it into irreducibles ---since \( K \) is a field, the polynomial ring \( K[x] \) is a PID and thus a UFD---, and then \(  d \)
\end{document}
