\documentclass[12pt,oneside]{book}

\input{preamble-apunts.tex}
\input{commands-analisi.tex}

\title{Real Analysis}
\author{Arnau Mas}
\date{2019}

\begin{document}
\maketitle

\frontmatter
\pagestyle{plain}
These are notes gathered during the subject \emph{Anàlisi Real i Funcional} as taught by Joan Orobitg between September 2019 and January 2020.

\mainmatter

\part{Measure Theory}
\chapter{Measure spaces}
\begin{definition}[\( \sigma \)-algebra]
	We say a family of subsets \( \A \subseteq \P(X) \) of a set \( X \) is a \( \sigma \)-algebra over it if
	\begin{points}
	\item \( \emptyset, X \in \A \),
	\item \( \A \) is closed under countable unions, i.e. if there is a countable set \( \{ A_i \}_{i \in \N} \subseteq \A \) then \( \bigcup_{i \in \N} A_i \in \A \),
	\item \( \A \) is closed under countable intersections, i.e. if there is a countable set \( \{ A_i \}_{i \in \N} \subseteq \A \) then \( \bigcap_{i \in \N} A_i \in \A \),
	\item \( \A \) is closed under complements, i.e. if \( A \in \A \) then \( A^c \in \A \).
	\end{points}
\end{definition}
Notice that if a collection of subsets is closed under countable unions and under complements then it is also closed under intersections since by De Morgan's laws a countable intersection is the complement of the union of complements. Similarly if it is closed under intersections and complements it is closed under unions. So when showing that a certain collection is a \( \sigma \)-algebra it is enough to show that is closed under one of unions or intersections.

\begin{example}
	The following are all examples of \( \sigma \)-algebras.
	\begin{points}
	\item For any set \( X \), \( \P(X) \) is a \( \sigma \)-algebra called the \emph{discrete \( \sigma \)-algebra}. It is the \emph{finest} \( \sigma \)-algebra since any other possible \( \sigma \)-algebra over \( X \) is contained in it.
	\item On the other hand, the \emph{coarsest} \( \sigma \)-algebra over any set \( X \) is simply \( \{ \emptyset, X \} \), meaning any other possible \( \sigma \)-algebra contains it. It is called the \emph{trivial \( \sigma \)-algebra}.
	\item If \( \A_1 \) and \( \A_2 \) are \( \sigma \)-algebras over a set \( X \) then so is \( \A_1 \cap \A_2 \).
	\item Given a family of subsets \( S \subseteq \P(X) \) then the \( \sigma \)-algebra generated by it is the intersection of all \( \sigma \)-algebras that contain it and it is the smallest \( \sigma \)-algebra that contains \( S \). We write it \( \sigma(S) \).
	\item The \emph{Borel \( \sigma \)-algebra} over a topological space \( X \) is the \( \sigma \)-algebra generated by the open sets of \( X \), written \( \B(X) \). Since a closed set is the complement of an open set the family of closed sets also generates the Borel \( \sigma \)-algebra.
	\end{points}
\end{example}
The pair formed by a set and its \( \sigma \)-algebra is called a \emph{measurable space}.

\begin{definition}[Measure]
	Let \( (X,\A) \) be a measurable space. A measure is a map \( \mu \colon A \to [0,\infty] \) such that the following are true
	\begin{points}
	\item \( \mu(\emptyset) = 0 \).
	\item If \( \{ A_i \}_{i \in \N} \subseteq \A \) is a family of pairwise disjoint sets of finite measure then
		\begin{equation*}
			\mu\left(\bigcup_{i \in \N} A_i\right) = \sum_{i \in \N} \mu(A_i). 
		\end{equation*}
	\end{points}
\end{definition}
A measurable space equipped with a measure is called a \emph{measure space}.

\begin{example}
	The following are all examples of measures.
	\begin{points}
	\item Consider a measurable space \( X \) with the discrete \( \sigma \)-algebra. Then, for any subset \( A \subseteq X \) we define \( \mu(A) = \abs{A} \) if \( A \) is finite and \( \mu(A) = \infty \) if \( A \) is infinite. This is the \emph{counting measure}, for obvious reasons.
	\item On a finite measurable space \( X \) with the discrete \( \sigma \)-algebra we define for any subset \( A \subseteq X \)
		\begin{equation*}
			\mu(A) = \frac{\abs{A}}{\abs{X}}.
		\end{equation*}
		This is a special case of a probability measure since \( \mu(X) = 1 \). In fact a probability is exactly a measure satisfying \( \mu(X) = 1 \).
	\item On a measurable space \( X \) with any \( \sigma \)-algebra fix a point \( x \in X \) and define \( \mu(A) = 1 \) if \( x \in A \) and \( \mu(A) = 0 \) otherwise. This is called the \emph{Dirac measure}.
	\end{points}
\end{example}

\chapter{The Lebesgue measure}
A question worth asking is whether any measurable space can be made into a measure space. Caratheódory's extension theorem gives an affirmative answer to the question provided we give a starting point for the measure. Roughly speaking the starting point consists of specifying the measure of a collection of subsets, subject to some requirements, which can then be extended to a measure on the whole of the \( \sigma \)-algebra. In this section we explore a particular case of this construction on \( \R^n \) which is known as the \emph{Lebesgue measure}.

The main motivation behind the Lebesgue measure is to rigorously generalise the idea of length ---in the case of \( \R \)---, area ---in the case of \( \R^2 \)--- and volume ---in the case of \( \R^n \)--- to arbitrary dimension and for as many subsets as possible. The starting point will be the rectangles (segments in \( \R \), rectangles in \( \R^2 \), prisms in \( \R^3 \)--- for which their volume is clear: it is simply the product of the length of the sides. 

\section{The Lebesgue exterior measure}
As we said, the starting point for the construction will be rectangles. Let's lay down the precise definitions.
\begin{definition}[Interval]
	An \emph{interval} \( I \) is a subset of \( \R \) with the property that if \( a, b \in I \) then \( c \in I \) whenever \( a < c < b \). It can be shown that if an interval is bounded then it must be one of \( [a,b] \), \( (a,b) \), \( [a,b) \) or \( (a,b] \). \( a \) and \( b \) are called the \emph{endpoints} of the interval and we will write \( \langle a,b \rangle \) for any interval with endpoints \( a \) and \( b \).

The length of an interval with endpoints \( a \) and \( b \) is defined to be \( \abs{b - a} \).
\end{definition}

\begin{definition}[Rectangle]
	An (\( n \)-dimensional) \emph{rectangle} \( R \) is the product of \( n \) intervals, that is
	\begin{equation*}
		R = \langle a_1, b_1 \rangle \times \cdots \times \langle a_n, b_n \rangle.
	\end{equation*}
	The \emph{volume} of a rectangle is defined to be
	\begin{equation*}
		v(R) = \abs{b_1 - a_1} \cdot \cdots \cdot \abs{b_n - a_n}.
	\end{equation*}
\end{definition}
These two definitions of (hopefully) clear concepts are perhaps needlessly fussy but it pays to be precise in the beginning.

\begin{definition}[Exterior measure]
	We define the \emph{Lebesgue exterior measure} or simply \emph{exterior measure} as
	\begin{equation*}
		\inf \left\{ \sum_{j = 1}^{\infty} v(R_j) \mid A \subseteq \bigcup_{j = 1}^{\infty}R_j \text{, }R_j\text{ rectangles} \right\}.
	\end{equation*}
	We will denote it by \( \ext{A} \).
\end{definition}
The intuition behind the exterior measure is as follows: given any set, cover it with rectangles and add up their volumes. Then try to refine the covering by acheiving less total area. The infimimum of the volumes of all possible covers is the exterior measure. In two dimensions this describes trying to literally cover the set by a patchwork of rectangles finer and finer that approximates the area of the set in question.

Also, given that the volume of a rectangle is always positive, the set we are taking the infimum of is bounded below by zero and so its infimimum always exists and is non-negative. Thus the exterior measure exists for any set. 

\begin{example}
	It is impractical to use the definition to directly compute the exterior measure of a given set. However here we calculate the exterior measure of various classes of sets which constitute relatively easy examples.
	\begin{points}
	\item The exterior measure of a point is 0. Indeed, let \( a \in \R^n \) and consider the square of center \( a \) and side \( \epsilon \), \( Q_\epsilon(a) \)\footnote{More precisely, if \( a = (a_1, \cdots, a_n) \) then \( Q_\epsilon(a) = (a_1 - \frac{\epsilon}{2}, a_1 + \frac{\epsilon}{2}) \times \cdots \times (a_1 - \frac{\epsilon}{2}, a_1 + \frac{\epsilon}{2}) \).}. Then \( Q_\epsilon(a) \) is certainly a cover of \( \{ a\} \) and has volume \( \epsilon^n \). That is, \( \ext{\{ a \}} \leq \epsilon^n \). Since \( \epsilon \) can be as small as we wish we conclude \( \ext{\{ a \}} = 0 \).

	\item A segment in \( \R^n \) (with \( n > 1 \)) has exterior measure 0. If the segment has length \( L \) then we can cover it with a rectangle of length \( L \) and whose all other sides have length \( \delta \). Then its total volume is \( L\delta^{n-1} \) and the exterior measure of the segment is bounded by it. And since \( \delta \) can be made as small as we want, we conclude the exterior measure must be 0. The details of the proof are a little cumbersome but the idea is hopefully clear.

	\item In general any (sufficiently well-behaved) bounded subset of a hyperspace of dimension \( k \) inside \( \R^n \) with \( k < n \) has zero exterior measure. The idea is a generalisation of the previous two examples: the set can be covered by an \( n \)-dimensional hypercube in such a way that \( n - k \) of its sides can be shrunk as much as one whishes and so the total volume of the cube goes to zero. Again, this is a little handwavy but the argument can be made precise. 

	\item Any countable set set of \( \R^n \) has zero exterior measure. Since a countable set is a countable union of points, cover one of the points with a square of volume \( \frac{\epsilon}{2} \), the next one with a square of volume \( \frac{\epsilon}{4} \), the following with a square of volume \( \frac{\epsilon}{8} \) and so on. The total volume of the cover is
		\begin{equation*}
			\sum_{n = 1}^{\infty} \frac{\epsilon}{2^n} = \epsilon 
		\end{equation*}
		which can be made as small as one wishes.
	\end{points}
\end{example}

\begin{lemma} \label{lemma:exterior measure with open sets}
	The exterior measure of any set is the same even if only open covers are considered.
\end{lemma}
\begin{proof}
	Let's for the moment write \( M^*(A) \) for the outer measure of a set considering only open covers. It is clear that \( \ext{A} \leq M^*(A) \) since a cover with open rectangles of \( A \) is still a cover by rectangles of \( A \) and so \( M^\ast(A) \) should be at least as big as \( \ext{A} \).

	Now we prove the reverse inequality, \( M^\ast(A) \leq \ext{A} \). If \( \{ R_i \}_{i = 1}^{\infty} \) is a cover of \( A \) by rectangles then
	\begin{equation*}
		\sum_{i = 1}^{\infty} v(R_i) = \sum_{i = 1}^{\infty} v(\mathring{R}_i)  
	\end{equation*}
	since a rectangle and its interior have the same endpoints. In general, however, it is not the case that
	\begin{equation*}
		\bigcup_{i = 1}^{\infty} R_i \subseteq \bigcup_{i = 1}^{\infty} \mathring{R}_i
	\end{equation*}
	since the interior of a set is contained in the set itself and not the other way (as should be the case) and in fact we might not even cover \( A \) anymore.

	To mend this we can simply dilate the interiors. In detail, given a rectangle \( R = \langle a_1, b_1 \rangle \times \cdots \times \langle a_n,b_n \rangle \) to be
	\begin{equation*}
		\lambda R = \lambda \langle a_1, b_1 \rangle \times \cdots \times \lambda \langle a_n,b_n \rangle
	\end{equation*}
	where by definition
	\begin{equation*}
		\lambda \langle a, b \rangle = \left\langle \frac{a+b}{2} - \lambda \frac{b - a}{2}, \frac{a + b}{2} + \lambda\frac{b - a}{2} \right\rangle.
	\end{equation*}
	This is all a very complicated way of saying we slightly inflate the rectangles while keeping their centers the same. It should be clear that if \( \lambda > 1 \) then \( R \subseteq \lambda \mathring{R} \) and \( v(\lambda R) = \lambda^n v(R) \). And so
	\begin{equation*}
		A \subseteq \bigcup_{i = 1}^{\infty} R_i \subseteq \bigcup_{i = 1}^{\infty} \lambda \mathring{R}_i.
	\end{equation*}
	Then, since \( \{ \lambda \mathring{R}_j \}_{j = 1}^{\infty} \) is a cover of \( A \) by open rectangles we have
	\begin{equation*}
		M^*(A) \leq \sum_{j = 1}^{\infty} v(\lambda \mathring{R}_j) = \lambda^n \sum_{j = 1}^{\infty} v(R_j).
	\end{equation*}
	Letting \( \lambda \to 1 \) we obtain that for any cover of \( A \) by rectangles \( \{ R_j \}_{j = 1}^\infty \) then
	\begin{equation*}
		M^*(A) \leq \sum_{j = 1}^{\infty} v(R_j)
	\end{equation*}
	and so \( M^*(A) \leq \ext{A} \) as we wanted.
\end{proof}

\begin{lemma} \label{lemma:exterior measure of rectangle}
	The exterior measure of a rectangle is exactly its volume.
\end{lemma}
\begin{proof}
	Let \( R \) be a rectangle. It is clear that \( \ext{R} \leq v(R) \) since \( R \) covers itself. We need to show then that \( v(R) \leq \ext{R} \). If \( \{ R_j \}_{j = 1}^\infty \) is a cover of \( R \) then we wish to conlcude that
	\begin{equation*}
		v(R) \leq \sum_{j = 1}^{\infty}v(R_j). 
	\end{equation*}

	We can without loss of generality assume that we are dealing with a closed rectangle since \( v(R) = v(\bar{R}) \). And since rectangles are bounded they are compact. Using the previous lemma we need only consider covers by open rectangles and by compactness we can further limit our scope to finite open covers. Now all that is left is to show that if a rectangle is covered by a finite amount of other rectangles then their combined volume is greater than that of the the original rectangle. 

	Let, then, \( R = \langle a_1,b_1 \rangle \times \cdots \times \langle a_n,b_n \rangle \) be a rectangle and \( \{ R_j \}_{j = 1}^N \) be a cover of \( R \) with \( R_j = \langle a^j_1,b^j_1 \rangle \times \cdots \times \langle a^j_n,b^j_n \rangle \). Then we take the projection onto the \( i \)-th dimension and we have that
	\begin{equation*}
		\langle a_i, b_i \rangle \subseteq \bigcup_{j = 1}^N \langle a^j_i, b^j_i \rangle.
	\end{equation*}
	Let \( A_i = \min \{ a^1_i, \cdots, a^N_i \} \) and \( B_i = \max \{ b^1_i, \cdots, b^N_i \} \). Then we have \( \abs{b^j_i - a^j_i} \leq \abs{B_i - A_i} \) and \todo{Finish this proof}

	This last part of the proof consists mainly of technical details. The main insight is that since we need only look at closed rectangles and open covers then we can, by compactness, reduce potentially infinite covers to finite ones and then we can take maximums and minimums without concern.
\end{proof}

{
	\def\currentprefix{prop:properties of exterior measure}	
	\begin{proposition}[Properties of the exterior measure] \label{prop:properties of exterior measure}
		The following are some properties of the exterior measure
		\begin{points}
		\item \locallabel{i} \( \ext{\emptyset} = 0 \).
		\item \locallabel{ii} The exterior measure is increasing, that is if \( A \subseteq B \) then \( \ext{A} \leq \ext{B} \). 
		\item \locallabel{iii} The exterior measure is countably subadditive, i.e.
			\begin{equation*}
				\ext{\bigcup_{j = 1}^\infty A_j} \leq \sum_{j = 1}^{\infty} \ext{A_j}. 
			\end{equation*}
		\item \locallabel{iv} The exterior measure is invariant under translations.
		\item \locallabel{v} If \( A \subseteq \R^n \) and \( \lambda \in \R \) then \( \ext{\lambda A} = \lambda^n \ext{A} \)\footnote{The notation \( \lambda A \) does not refer to a dilation as used in the proof of \cref{lemma:exterior measure with open sets} but rather to the image of \( A \) under scalar multiplication by \( \lambda \) which is more standard.}.
		\item \locallabel{vi} If a set \( A \) satisfies \( \mathring{R} \subseteq A \subseteq \bar{R} \) for a rectangle \( R \) then \( \ext{A} = v(R) \).
		\end{points}
	\end{proposition}
	\begin{proof}
		\localref{i} follows from the fact that any cover is a cover of the empty set. \localref{ii} is because any cover of \( B \) is a cover of \( A \) so \( \ext{A} \) must be less than \( \ext{B} \).

		Proving \localref{iii} requires a bit more work. We may assume that every one of the \( A_j \) has finite exterior measure since otherwise we are dealing with a vacuous statement. Let \( \{ R_i^j \}_{i = 1}^\infty \) be a cover of \( A_j \) such that 
		\begin{equation*}
			\sum_{i = 1}^{\infty} v(R_i^j) \leq \ext{A_j} + \frac{\epsilon}{2^j}. 
		\end{equation*}
		Then
		\begin{equation*}
			\bigcup_{j=1}^\infty A_j \subseteq \bigcup_{j=1}^\infty \bigcup_{i=1}^\infty R_i^j
		\end{equation*}
		so
		\begin{equation*}
			\ext{\bigcup_{j=1}^\infty A_j} \leq \sum_{j=1}^\infty \sum_{i=1}^\infty v(R_i^j) \leq \sum_{j = 1}^{\infty} \ext{A_j} + \frac{\epsilon}{2^j} = \sum_{j = 1}^{\infty} \ext{A_j} + \epsilon.
		\end{equation*}
		And then by letting \( \epsilon \to 0 \) we obtain the countable subadditivity.	

		It should be clear that the volume of a rectangle is invariant under translations. This means that if we have a cover of a set \( A \) then we can transform it, by a translation, into a cover of the translated set \( A + x \) of the same total volume, and viceversa. And so it follows that \( \ext{A} = \ext{A + x} \). This proves \localref{iv}.

		The proof of \localref{v} is very similar. Again, it should be clear that if we scale a rectangle of dimension \( n \) by a factor of \( \lambda \) then its volume picks up a factor of \( \lambda^n \). So, given a cover of \( A \) with total volume \( V \) we can scale it by \( \lambda \) and we obtain a cover of \( \lambda A \) with volume \( \lambda^n V \), and viceversa. Thus we see that \( \ext{\lambda A} = \lambda^n \ext{A} \).

		It follows immediately from \localref{ii} that \( \ext{\mathring{R}} \leq \ext{A} \leq
		\ext{\bar{R}} \). And then, using \cref{lemma:exterior measure of rectangle} we find
		\( \ext{\mathring{R}} = \ext{\bar{R}} = v(R) \) and so \( \ext{A} = v(R) \). 
	\end{proof}
}

\section{Measurable sets}
If the measure we are constructing is to be a useful generalization of the notion of volume we should expect the measure of the union of disjoint sets to be the sum of their measures. With the exterior measure this is the case for most well-behaved sets, but there exist counterexamples. The solution to this problem is to restrict ourselves to a smaller class of sets which we will call the measurable sets.
\begin{definition}[Measurable set]\label{def:measurable set}
	We say a set \( E \subseteq \R^n \) is \emph{measurable} if for any other set \( A \subseteq \R^n \) it is true that
	\begin{equation*}
		\ext{A} \geq \ext{E \cap A} + \ext{E^c \cap A}.
	\end{equation*}
The set \( A \) is sometimes called a \emph{test set}.
\end{definition}

Notice that because the exterior measure is subadditive we get the other inequality for free so we could have required equality in the definition of a measurable set without being more restrictive.

\begin{example} \label{exe:measurable sets}
	The following are various examples of measurable sets
	\begin{points}
	\item \( \R^n \) is measurable since \( \R^n \cap A = A \) and \( (\R^n)^c \cap A = \emptyset \).
	\item Similarly \( \emptyset \) is also measurable.
	\item Any set of zero exterior measure, also called a \emph{null set}, is measurable. Indeed, if \( \ext{E} = 0 \) since \( E \cap A \subseteq E \) then \( \ext{E \cap A} = 0 \) and
		\begin{equation*}
			\ext{E \cap A} + \ext{E^c \cap A} = \ext{E^c \cap A} \leq \ext{A}.
		\end{equation*}
	\end{points}
\end{example}

The collection of measurable subsets of \( \R^n \) forms a \( \sigma \)-algebra. To prove this we will first show a preliminary result. 
\begin{proposition}
	The collection of measurable subsets is stable under finite unions. Furthermore the exterior measure is finitely additive, that is if \( E_1, \cdots, E_n \) are measurable sets and are pairwise disjoint then 
	\begin{equation*}
		\ext{\bigcup_{k = 1}^n E_k} = \sum_{k = 1}^{n} \ext{E_k}. 
	\end{equation*}
\end{proposition}
\begin{proof}
	Let \( \M \) denote the set of measurable subsets of \( \R^n \). It is sufficient to show that if \( E, F \in \M \) then \(  E \cup F \in \M \) since we can then prove by induction that any finite union of measurable sets is measurable. For any \( A \subseteq \R^n \) we have
	\begin{equation*}
		\ext{A \cap (E \cup F)} + \ext{A \cap (E \cup F)^c} = \ext{(A \cap E) \cup (A \cap F)} + \ext{A \cap E^c \cap F^c}.
	\end{equation*}
	We may use the identity of sets \( (A \cap E) \cup (A \cap F) = (A \cap E) \cup (A \cap E^c \cap F) \) and subadditivity to get
	\begin{align*}
		\ext{A \cap (E \cup F)} & + \ext{A \cap (E \cup F)^c} = \\
														& = \ext{(A \cap E) \cup (A \cap E^c \cap F)} + \ext{A \cap E^c \cap F^c} \\
														& \leq \ext{A \cap E} + \ext{(A \cap E^c) \cap F} + \ext{(A \cap E^c) \cap F^c} \\
														& = \ext{A \cap E} + \ext{A \cap E^c} = \ext{A},
	\end{align*}
	where we have used the measurability of \( E \) and \( F \) in the last two steps. 

	We now prove the finite additivity. Let \( E_1, \cdots, E_n \) be pairwise disjoint measurable sets. Then using \( A \cap \left(\bigcup_{k = 1}^n	E_k\right) \) as a test set and \( E_n \) as the measurable set we have, by definition of measurability
	\begin{align*}
		\ext{A \cap \left(\bigcup_{k = 1}^n	E_k\right)} & = \ext{A \cap \left(\bigcup_{k = 1}^n	E_k\right) \cap E_n} + \ext{A \cap \left(\bigcup_{k = 1}^n	E_k\right) \cap E_n^c} \\
																										& = \ext{A \cap E_n} + \ext{A \cap \left(\bigcup_{k = 1}^{n-1}	E_k\right)}.
	\end{align*}
	By induction we find
	\begin{equation*}
		\ext{A \cap \left(\bigcup_{k = 1}^n	E_k\right)} = \sum_{k = 1}^{n} \ext{A \cap E_k} 
	\end{equation*}
	and taking \( A = \bigcup_{k = 1}^n E_k \) we obtain
	\begin{equation*}
		\ext{\bigcup_{k = 1}^n E_k} = \sum_{k = 1}^{n}\ext{E_k} 
	\end{equation*}
	as we wanted.
\end{proof}

\begin{proposition}
	The collection \( \M \) of measurable subsets of \( \R^n \) is a \( \sigma \)-algebra.
\end{proposition}
\begin{proof}
	We have already seen in \cref{exe:measurable sets} that \( \R^n \) and \( \emptyset \) are both measurable. It is also immediate that the complement of a measurable set is also measurable. All that remains to be shown is that \( \M \) is closed under countable unions. 

	Let \( \{ E_k \}_{k = 1}^\infty \) be a countable family of measurable subsets. A first observation is that we may, without loss of generality, assume that the \( E_k \) are pairwise disjoint. Indeed, define \( F_1 = E_1 \) and \( F_k = E_{k} - \bigcup_{j = 1}^{k-1}E_j \). The \( F_k \) are disjoint by construction. They are also all measurable by virtue of being finite intersections and unions of measurable sets and more importantly
	\begin{equation*}
		\bigcup_{k = 1}^\infty E_k = \bigcup_{k = 1}^\infty	F_k.
	\end{equation*}
	What this means is that any union of measurable sets is equal to the union of some other pairwise disjoint measurable sets. So if we manage to show that countable unions of pairwise disjoint measurable sets are measurable we are done. 

	Let's get to it then. We want to show that
	\begin{equation*}
		\ext{A} \geq \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}.
	\end{equation*}
	We start from the fact that finite unions of measurable sets are measurable and so for any \( n \in \N \)
	\begin{equation*}
		\ext{A} \geq \ext{A \cap \left(\bigcup_{k = 1}^n E_k\right)} + \ext{A \cap \left(\bigcup_{k = 1}^n E_k\right)^c}.
	\end{equation*}
	Now notice that 	
	\begin{equation*}
		\bigcap_{k = 1}^N E_k \subseteq \bigcap_{k = 1}^\infty E_k
	\end{equation*}
	so when we take complements the inclusion reverses and we get
	\begin{equation*}
		\left(\bigcap_{k = 1}^\infty E_k\right)^c \subseteq \left(\bigcap_{k = 1}^N E_k\right)^c.
	\end{equation*}
	Therefore
	\begin{equation*}
		\ext{A \cap \left(\bigcup_{k = 1}^n E_k\right)^c} \geq \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}
	\end{equation*}
	which takes care of the second term.

	For the first term, we use the distributivity of intersection over unions and finite additivity ---remember we are assuming the \( E_k \) to be pairwise disjoint--- to get
	\begin{equation*}
		\ext{A \cap \left(\bigcup_{k = 1}^n E_k\right)} = \ext{\bigcup_{k = 1}^n A \cap E_k} = \sum_{k = 1}^{n} \ext{A \cap E_k}.
	\end{equation*}

	All together reads
	\begin{equation*}
		\ext{A} \geq \sum_{k = 1}^{n} \ext{A \cap E_k} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}.
	\end{equation*}
	By taking the limit \( n \to \infty \) we get
	\begin{equation*}
		\ext{A} \geq \sum_{k = 1}^\infty \ext{A \cap E_k} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}.
	\end{equation*}
	Finally, we use subadditivity to arrive at the desired result,
	\begin{align*}
		\ext{A} & \geq \sum_{k = 1}^\infty \ext{A \cap E_k} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c} \\
						& \geq \ext{\bigcup_{k = 1}^\infty A \cap E_k} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c} \\
						& \geq \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}.
	\end{align*}
\end{proof}

We now have a \( \sigma \)-algebra defined on \( \R^n \), which makes into a measurable space. To make it into a measure space we restrict the exterior measure to the measurable sets. We have to check that this is an honest to goodness measure. We have already seen that the measure of the empty set is 0, but we have to show that the measure is additive for disjoint unions.

\begin{proposition}
	The exterior measure of the union of disjoint sets is the sum of their measures. That is, if \( E_k \) are pairwise disjoint measurable sets then
	\begin{equation*}
		\ext{\bigcup_{k = 1}^\infty E_k} = \sum_{k = 1}^{\infty} \ext{E_k}. 
	\end{equation*}
\end{proposition}
\begin{proof}
	We showed in the proof of the previous proposition that
	\begin{equation*}
		\ext{A} \geq \sum_{k = 1}^\infty \ext{A \cap E_k} + \ext{A \cap \left(\bigcup_{k = 1}^\infty E_k\right)^c}.
	\end{equation*}
	Take as a test \( A = \bigcup_{k = 1}^\infty E_k \), then, using the fact that the \( E_k \) are pairwise disjoint,
	\begin{equation*}
		\ext{\bigcup_{k = 1}^\infty E_k} \geq \sum_{k = 1}^\infty \ext{E_k} + \ext{\emptyset} = \sum_{k = 1}^\infty \ext{E_k}.
	\end{equation*}
	The reverse inequality is a statement of subadditivity. So we get
	\begin{equation*}
		\ext{\bigcup_{k = 1}^\infty E_k} = \sum_{k = 1}^\infty \ext{E_k}.
	\end{equation*}
\end{proof}

\section{The structure of measurable sets}
In this section we will give a number of results that shed light into the nature of measurable sets. The \( \sigma \)-algebra \( \M \) is not exactly the Borel \( \sigma \)-algebra \( \B(\R) \). However measaurable sets are really close to Borel sets, as we will see.

{\def\currentprefix{theo:characterization of measurable sets}
\begin{theorem}\label{theo:characterization of measurable sets}
	For any subset \( E \subseteq \R^n \) the following are equivalent:
	\begin{points}
	\item \locallabel{i} \( E \) is measurable.
	\item \locallabel{ii} For all \( \epsilon > 0 \) there is an open set \( G_{\epsilon} \supseteq E \) such that \(  \ext{G_{\epsilon} - E} < \epsilon \).
	\item \locallabel{iii} For all \( \epsilon > 0 \) there is a closed set \( F_{\epsilon} \subseteq E \) such that \(  \ext{E - F_{\epsilon}} < \epsilon \).
	\item \locallabel{iv} For all \( \epsilon > 0 \) there are an open set \( G_{\epsilon} \) and a closed set \( F_{\epsilon} \) such that \( F_{\epsilon} \subseteq E \subseteq G_{\epsilon} \) and \( \ext{G_{\epsilon} - F_{\epsilon}} < \epsilon \).
	\end{points}
\end{theorem}
\begin{proof}
	Let's first show \localref{i}\( \implies \)\localref{ii}. We tackle first the case \(
	\ext{E} < \infty \). Then, by definition of the exterior measure there is a cover of \( E \) by open rectangles, \( \{ R_j \}_{j = 1}^\infty \) such that
	\begin{equation*}
		\sum_{j = 1}^{\infty} v(R_j) < \ext{E} + \epsilon.
	\end{equation*}
	Let \( G_\epsilon = \bigcup_{j = 1}^\infty R_j \). This is an open set that contains \(
	E \). Thus \( G_\epsilon \cup E = E \) and since \( E \) is measurable by hypothesis we
	have
	\begin{equation*}
		\ext{G_\epsilon - E} = \ext{G_\epsilon} - \ext{E} \leq \sum_{j = 1}^{\infty}v(R_j) - \ext{E} < \epsilon.
	\end{equation*}

	There is a usual trick to deal with the case \( \ext{E} = \infty \), which is to write
	it as a countable union of sets of finite measure. Let \( E_N \defeq E
	\cap B(0,N) \). Then every \( E_N \) has finite measure since it is, by construction,
	contained inside of a	ball of finite radius. Furthermore we have
	\begin{equation*}
		E = \bigcup_{N = 1}^{\infty} E_N.
	\end{equation*}
	The inclusion \( \bigcup_{N = 1}^\infty E_N \subseteq E \) is clear, since \( E_N
	\subseteq E \). For the other inclusion we use that if \( x \in E \) then \( x \in E_N
	\) for \( N \geq \norm{x} \).

	Since every \( E_N \) is measurable and has finite measure there exists for each \( N
	\geq 1 \) an open set \( G_N \supseteq E_N \) such that
	\begin{equation*}
		\ext{G_N - E_N} < \frac{\epsilon}{2^N}.
	\end{equation*}
	It should be clear that the \( G_N \) are an open cover of \( E \). Let \( G_\epsilon \)
	be their union, so that \( G_\epsilon \supseteq E \). Now we have
	\begin{equation*}
		G_\epsilon - E = \bigcup_{N = 0}^\infty (G_N - E) \subseteq \bigcup_{N = 0} (G_N -
		E_N)
	\end{equation*}
	thus
	\begin{equation*}
		\ext{G_\epsilon - E} \leq \ext{\bigcup_{N = 1}^\infty(G_N - E_N)} \leq \sum_{N = 1}^{\infty}
		\ext{G_N - E_N} < \sum_{N = 1}^{\infty} \frac{\epsilon}{2^N} = \epsilon  
	\end{equation*}
	as we wanted.	

	We now prove \localref{ii}\( \implies \)\localref{i}.	For each \( n \in \N \) let \( G_n
	\supseteq E \) be an open set such that \( \ext{G_n - E} < \frac{1}{n} \) using our
	hypothesis \localref{ii}. Then let \( N \defeq \bigcap_{N = 1}^\infty G_N - E \). It
	follows \( N \) is a null set, since for each \( n \in \N \) we have
	\begin{equation*}
		\ext{N} = \ext{\bigcap_{n = 1}^\infty G_n - E} \leq \ext{G_n - E} < \frac{1}{n}
	\end{equation*}
	so it must be \( \ext{N} = 0 \). In particular \( N \) is measurable. 

	Now notice that \( N \cup E = \bigcap_{n = 1}^\infty G_n \), thus, since \( N \) and \( E
	\) are disjoint by construction
	\begin{equation}\label{eq:measurable set is intersection of open sets minus null set}
		E = \bigcap_{n = 1}^{\infty} G_n - N.
	\end{equation}
	This means \( E \) is measurable. Indeed, every \( G_n \) is measurable since it is
	open, so their intersection is also measurable. We showed before that \( N \) is
	measurable since it is null, so \( E \) must be measurable since it is a difference of
	measurable sets.

	\parbreak

	Let's show \localref{i}\( \iff \)\localref{iii}. For the implication
	\localref{i}\( \implies \)\localref{iii} apply \localref{ii} to \( E^c \). That is,
	there is an open set \( G_\epsilon \supseteq E^c \) such that \( \ext{G_\epsilon - E^c}
	< \epsilon \). Now \( F_\epsilon \defeq G_\epsilon^c \) is closed and
	\begin{equation*}
		F_\epsilon = G_\epsilon^c \subseteq (E^c)^c = E.
	\end{equation*}
	Furthermore
	\begin{equation*}
		E - F_\epsilon = E \cap F_\epsilon^c = E \cap G_\epsilon = (E^c)^c \cap G_\epsilon =
		G_\epsilon - E^c
	\end{equation*}
	which means \( \ext{E - F_\epsilon} < \epsilon \) as we wanted to show. 

	To prove the converse, \localref{iii}\( \implies \)\localref{i} we use an argument very
	similar to the proof of \localref{ii}\( \implies \)\localref{i}. For every \(
	n \in \N \) let \( F_n \subseteq E \) be a closed set such that \( \ext{E - F_n} <
	\frac{1}{n} \). Then let
	\begin{equation*}
		N \defeq E - \bigcup_{n = 1}^{\infty} F_n.
	\end{equation*}
	It is easy to see that \( N \) is a null set, and therefore measurable. Finally from
	\begin{equation}\label{eq:measurable set is union of closed sets and null set}
		E = N \cup \bigcup_{n = 1}^\infty F_n
	\end{equation}
	one concludes \( E \) is measurable.

	\parbreak

	Finally we will prove that \localref{iv} is equivalent to \localref{ii} and
	\localref{iii}, which in turn means it is equivalent to \localref{iv}.

	It is easy to see that \localref{iv} implies \localref{ii} and \localref{iii}. Indeed, if
	\( G_\epsilon \) and \( F_\epsilon \) satisfy the hypotheses of \localref{iv} then
	\begin{equation*}
		\ext{E - F_\epsilon} \leq \ext{G_\epsilon - F_\epsilon} < \epsilon
	\end{equation*}
	and 
	\begin{equation*}
		\ext{G_\epsilon - E} \leq \ext{G_\epsilon - F_\epsilon} < \epsilon.
	\end{equation*}

	We now prove the converse. If there exist \( G_{\epsilon/2} \) and \(
	F_{\epsilon/2} \) satisfying the conditions in \localref{ii} and \localref{iii} then it is
	easy to show that \( G_{\epsilon/2} - F_{\epsilon/2} = (G_{\epsilon/2} - E) \cup (E -
	F_{\epsilon/2}) \)
	which implies
	\begin{equation*}
		\ext{G_{\epsilon/2} - F_{\epsilon/2}} \leq \ext{G_{\epsilon/2} - E} + \ext{E -
		F_{\epsilon/2}} < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
	\end{equation*}
\end{proof}
}

\begin{corollary}
	A set \( E \subseteq \R^n \) is measurable if and only if it is a countable union of open
	sets minus a null set. Equivalently, \( E \) is measurable if and only if it is the
	union of a null set and a countable union of closed sets.
\end{corollary}
\begin{proof}
	It should be clear that a countable union of open sets minus a null set is measurable,
	as is a countable union of closed sets and a null set. The proof of the converse is
	essentially in the proof of \cref{theo:characterization of measurable sets}, namely
	\cref{eq:measurable set is intersection of open sets minus null set,eq:measurable set is
	union of closed sets and null set}.
\end{proof}

\chapter{The Lebesgue integral and integrable functions}
\begin{theorem}[Monotone Convergence] \label{theo:monotone convergence}
	Let \( f_n \colon E \subseteq \R \to [0,\infty] \) an increasing sequence of positive
	measurable functions, i.e. \( f_n \leq f_{n+1} \ae \), which converges pointwise almost everywhere to a measurable  function \( f \). Then
	\begin{equation*}
		\int_E f = \lim_{n \to \infty} \int_E f_n.
	\end{equation*}
\end{theorem}
\begin{proof}
	Observe that since the sequence of the \( f_n \) is increasing then so is the sequence
	of their integrals and therefore it has a limit ---although it is potentially not
	finite---. In particular we have
	\begin{equation*}
		\lim_{n \to \infty} \int_E f_n \leq \int_E f
	\end{equation*}
	since each of the \( f_n \) is bounded by \( f \). Therefore we need only show the
	reverse inequality,
	\begin{equation} \label{eq:integral of limit bounded by limit of integrals}
		\int_E f \leq \lim_{n \to \infty} \int_E f_n
	\end{equation}

	The theorem is easy to prove when the domain of integration has finite measure and the
	convergence of the \( f_n \) to \( f \) is almost everywhere uniform. In this case we
	have that for any \( \epsilon > 0 \) there is a term beyond which
	\begin{equation*}\label{eq:fn uniformly bounded by f}
		f(x) - f_n(x) \leq \epsilon
	\end{equation*}
	holds for almost all \( x \in E \). When we integrate over \( E \), ignoring the null
	set where \cref{eq:fn uniformly bounded by f} does not hold, we get
	\begin{equation*}
		\int_E f_n \geq \int_E f - \int_E \epsilon = \int_E f - \epsilon m(E).
	\end{equation*}
	Letting \( \epsilon \to 0 \) and \( n \to \infty \) we get the result we wanted.

	Let's now tackle the general case. We will show it by way of the definition of the
	Lebesgue integral, i.e. by working with simple functions that are bounded by \( f \).
	Let, then, \( s \) be a positive measurable simple function on \( E \) such that \( s
	\leq f \). We also introduce a parameter \( c \in (0,1) \) to give us some wiggle
	room. Then define
	\begin{equation*}
		E_n = \{ x \in E \mid cs(x) \leq f_n(x) \}.
	\end{equation*}
	Since \( E_n = (cs - f_n)^{-1}([-\infty, 0]) \) it is measurable.	Notice that beyond a
	certain \( n \) the \( E_n \) are not empty. Indeed, for all \(
	x \in E\) we have \( s(x)	\leq f(x) \), thus \( cs(x) < f(x) \) and so, since \(
	f_n(x) \) converges to \(	f(x) \), beyond some \( n \) we must have \( cs(x) < f_n(x) <
	f(x) \) which means \( x \in E_n \). Also, it should be clear	that \( E_n \subseteq
	E_{n+1} \) because of the	monotonicity the \( f_n \). Finally, we have
	\begin{equation*}
		E - N = \bigcup_{n = 1}^\infty E_n
	\end{equation*}
	where \( N \) is a set of measure zero, which reflects the fact that the \( f_n \)
	converge to \( f \) almost everywhere on \( E \).

	Consider a disjoint representation of \( s \), \( s = \sum_{k = 1}^{N} \lambda_k
	\chi_{A_k} \) where the \( A_k \subseteq E \) are pairwise disjoint measurable sets.
	Then we have
	\begin{equation*}
		\int_{E_n} s = \sum_{k = 1}^{N} \lambda_k m(A_k \cap E_n). 
	\end{equation*}
	Then when \( n \to \infty \) since the \( E_n \) increase to \( E-N \),	thus \( A_k \cap
	E_n \) increases to \( A_k - N \). Then, by continuity from below of the Lebesgue
	measure
	\begin{equation*}
		m(A_k \cap E_n) \xrightarrow{n \to \infty} m(A_k - N) = m(A_k)
	\end{equation*}
	Therefore, by the definition of the integral of a simple function,
	\begin{equation} \label{eq:limit of simple integrals}
		\int_{E_n} s = \sum_{k = 1}^{N} \lambda_k m(A_k \cap E_n) \xrightarrow{n \to \infty} \sum_{k = 1}^{N} \lambda_k m(A_k) = \int_E s. 
	\end{equation}

	On \( E_n \) we have \( cs \leq f_n \) which means
	\begin{equation*}
		c \int_{E_n} s \leq \int_{E_n} f_n \leq \int_{E} f_n.
	\end{equation*}
	Now we take the limit \( n \to \infty \) and using \cref{eq:limit of simple integrals}
	we find 
	\begin{equation*}
		c \int_E s \leq \lim_{n \to \infty} \int_E f_n.
	\end{equation*}
	And by letting \( c \to 1 \) we obtain
	\begin{equation*}
		\int_E s \leq \lim_{n \to \infty} \int_E f_n.
	\end{equation*}
	We have just shown that the integral of any simple function bounded by \( f \) is bounded
	by the limit of the integrals \( \int_E f_n \). Thus, the supremum over all simple
	functions bounded by \( f \), which is, by definition the integral of \( f \), is also
	bounded by it,
	\begin{equation*}
		\int_E f \leq \lim_{n \to \infty} \int_E f_n,
	\end{equation*}
	as we wanted.
\end{proof}

The Monotone Convergence Theorem implies a couple of other important results.
\begin{theorem}[Beppo Levi]
	Let \( f_n \to E \subseteq \R \to [0,\infty] \)	be positive measurable functions. Then
	\begin{equation*}
		\int_E \sum_{n = 1}^{\infty} f_n = \sum_{n = 1}^{\infty} \int_E f_n.  
	\end{equation*}
\end{theorem}
\begin{proof}
	Let \( F_N \) denote the \( N \)-th partial sum of the series. Since the \( f_n \) are positive, the \( F_N \) are increasing. We can then apply Monotone Convergence, \cref{theo:monotone convergence}.
\end{proof}
This result shows one of the advantages of the Lebesgue integral in front of the Riemann integral. In the Riemann theory of integration, one required uniform convergence to be able to exchange a series with an integral, whereas in this case pointwise convergence suffices. Notice, however, that the terms must be postive. 

\begin{theorem}[Fatou's Lemma]\label{theo:Fatou}
	Given a sequence of positive measurable functions, \( f_n \colon E \subseteq \R^n \to [0,
	\infty] \) then
	\begin{equation*}
		\int_E \liminf_{n \to \infty} f_n \leq \liminf_{n \to \infty} \int_E f_n.
	\end{equation*}
\end{theorem}
\begin{proof}
	We have, by definition
	\begin{equation*}
		\liminf_{n \to \infty} f_n(x) = \lim_{n \to \infty} \left(\inf_{m \geq f_n}
		f_m(x)\right).
	\end{equation*}
	Observe as well that 
	\begin{equation*}
		\inf_{m \geq n}f_n \leq \inf_{m \geq n+1}f_{m}
	\end{equation*}
	which means we can apply \nameref{theo:monotone convergence} to get
	\begin{equation*}
		\int_E \liminf_{n \to \infty} f_n = \int_{E} \lim_{n \to \infty} \left(\inf_{m \geq n}
		f_m\right) = \lim_{n \to \infty} \int_E \inf_{m \geq n} f_m.
	\end{equation*}
	When we write \( \inf_{m \geq n} f_m \) we mean	that we are taking the infimimum
	pointwise, which means \( \inf_{m \geq n} f_m \) need not coincide with any of the \( f_n
	\). At each point, however, we have for all \( m \geq n \), essentially by definition of
	the infimum,
	\begin{equation*}
		\inf_{m \geq n} f_m(x) \leq f_m(x)
	\end{equation*}
	which means
	\begin{equation*}
		\int_E \inf_{m \geq n} f_m \leq \int_{E} f_m
	\end{equation*}
	thus
	\begin{equation*}
		\int_E \inf_{m \geq n} f_m \inf_{m \geq n} \int_E f_m.
	\end{equation*}
	Finally we put it all together to get the desired bound
	\begin{equation*}
		\int_E \liminf_{n \to \infty} f_n = \lim_{n \to \infty} \int_E \inf_{m \geq n} f_m
		\leq \lim_{n \to \infty} \inf_{m \geq n} \int_E f_m = \liminf_{n \to \infty} \int_E
		f_n.
	\end{equation*}
\end{proof}

\begin{theorem}[Dominated Convergence] \label{theo:dominated convergence}
	Let \( f_n \colon E \subseteq \R^n \to \bar{\R} \) be a sequence of measurable functions which
	converge pointwise to a function \( f \colon E \to \bar{\R} \). If
	the \( f_n \) are almost everywhere dominated by an integrable function \( g \colon E
	\to \bar{\R} \), that is
	\begin{equation*}
		\abs{f_n(x)} \leq g(x) \aeon{E}
	\end{equation*}
	then \( f \) is integrable and
	\begin{equation*}
		\int_E \abs{f - f_n} \xrightarrow{n \to \infty} 0.
	\end{equation*}
	In particular
	\begin{equation*}
		\int_E f_n \xrightarrow{n \to \infty} \int_E f.
	\end{equation*}
\end{theorem}
\begin{proof}
	Observe that the \( f_n \) are integrable: they are measurable by assumption and
	\begin{equation*}
		\int_E \abs{f_n} \leq \int_E g < \infty 
	\end{equation*}
	since \( g \) is integrable. Similarly, \( f \) is also integrable. It is measurable by
	being the limit of measurable functions and since \( \abs{f_n(x)} \leq g(x) \ae \) it
	follows \( \abs{f(x)} \leq g(x) \ae \), which means \( f \) is integrable.

	Let \( h_n = \abs{f_n - f} \). We have
	\begin{equation*}
		h_n(x) = \abs{f_n(x) - f(x)} \leq 2g(x) \aeon{E}.
	\end{equation*}
	Now, \( h_n(x) \) goes to 0 as \( n \to \infty \) everywhere on \( E \) so
	\begin{equation*}
		\int_E 2g = \int_E \lim_{n \to \infty} (2g - h_n).
	\end{equation*}
	Since \( 2g(x) - h_n(x) \geq 0 \ae \) we can apply \nameref{theo:Fatou} ---restricting
	ourselves to \( E \) minus the null set where \( 2g(x) - h_n(x) \geq 0 \) may not
	hold---, to find
	\begin{equation*}
		\int_E 2g = \int_E \lim_{n \to \infty} (2g - h_n) \leq \liminf_{n \to \infty} \int_E
		2g - h_n
	\end{equation*}
	since \( \lim_{n \to \infty} (2g - h_n) = \liminf_{n \to \infty }(2g - h_n) \). Now,
	using standard properties of the limit inferior,
	\begin{align*}
		\int_E 2g & \leq \liminf_{n \to \infty} \int_E 2g - h_n = \liminf_{n \to \infty}
		\left(\int_E 2g - \int_E h_n\right) \\
							& = \int_E 2g + \liminf_{n \to \infty} \left(- \int_E h_n\right) \\
							& = \int_E 2g - \limsup_{n \to \infty} \int_E
							h_n.
	\end{align*}
	From this it follows that \( \limsup_{n \to \infty} \int_E h_n \leq 0 \), which means it
	is actually 0 since the \( h_n \) are positive. In fact, since they are positive we have
	that \( \liminf_{n \to \infty} \int_E h_n \geq 0 \). Since the limit superior is always
	greater than the limit inferior, we conclude both are 0 for \( \int_E h_n \) which means
	\begin{equation*}
		\int_E h_n = \int_E \abs{f_n - f} \xrightarrow{n \to \infty} 0,
	\end{equation*}
	as we wanted.	

	Finally we have
	\begin{equation*}
		\abs{\int_E f_n  - \int_E f} = \abs{\int_E f_n - f} \leq \int_E \abs{f_n - f} \to 0
	\end{equation*}
	which implies
	\begin{equation*}
		\int_E f_n \to \int_E f
	\end{equation*}
	as we wished.
\end{proof}

\section{Differentiation under the integral sign}

\begin{theorem}
	Let \( f \colon E \times I \to \R \) be a measurable function where \( E \subseteq \R^n
	\) is measurable and \( I	\subseteq \R \) is an interval. Write \( f_x \) for the
	function
	
	
	
\end{theorem}


\section{Applications of the theory of integration}
Once we have the various results of the theory of Lebesgue integration at out disposal we
can restate a number of concepts in terms of the Lebesgue integral. These include the
convolution of functions, differentiation under the integral sign and the change of
variable theorem. 

\subsection{Convolution}
The operation of convolution is defined on integrable functions. 

\begin{definition}[Convolution]
	Let \( f, g \in \L^1(\R^n) \) be two integrable functions. We define their
	\emph{convolution} \( f \ast g \) as
	\begin{equation*}
		(f \ast g)(x) \defeq \int_{\R^n} f(x - y) g(y) \d y.
	\end{equation*}
\end{definition}
If the functions \( f \) and \( g \) are continous and have compact support it is clear
that their convolution is finite everywhere. But in fact we can show that the convolution
of any two integrable functions is always integrable.

\begin{proposition}
	The convolution of any two integrable funcions is always integrable. In other words, if
	\( f, g \in \L^1(\R^n) \) then \( f \ast g \in \L^1(\R^n) \).
\end{proposition}
\begin{proof}
	To show that \( f \ast g \) is integrable we need to show that it is measurable and
	absolutely integrable. We can directly compute the integral of \(
	\abs{f \ast g }	\):
	\begin{align*}
		\int_{\R^n} \abs{f \ast g} & = \int_{\R^n} \int_{\R^n} \abs{f(x - y)} \abs{g(y)} \d y \d
		x \\
															 & = \int_{\R^n} \abs{g(y)} \int_{\R^n} \abs{f(x - y)} \d x
															 \d y \\
															 & = \int_{\R^n} \abs{g(y)} \d y \int_{\R^n} \abs{f(x - y)}
															 \d x \tag*{by Tonelli's Theorem} \\
															 & = \int_{\R^n} \abs{g} \int_{\R^n} \abs{f} < \infty
															 \tag*{since \( f,g \in \L^1(\R^n). \)}
	\end{align*}

	In the last step we made use of the change of variable theorem which we haven't shown yet.
	However it should not be difficult to convince yourself that it is true in this case since
	\( f(x - y) \) is merely \( f \) translated by \( y \), so its integral over \( \R^n \)
	should not change. 

	It is clear that \( h(x,y) = f(x - y)g(y) \) is measurable since it is the product of
	measuarable functions \todo{Not as clear}. We have just shown that it is absolutely integrable, so, by
	Fubini's Theorem we find that the integral of \( h \) with respect to \( y \), that is,
	\( f \ast g \) is measurable. From this we conclude that \( f \ast g \in \L^1(\R^n) \).
\end{proof}

The operation of convolution has a number of nice properties, namely it is associative and
commutative.
\begin{proposition}
	Convolution is an associative and commutative operation. That is, for any \( f, g, h \in
	\L^1(\R^n) \) we have
	\begin{equation*}
		(f \ast g) \ast h
	\end{equation*}
	and
	\begin{equation*}
		f \ast g = g \ast f.
	\end{equation*}
\end{proposition}
\begin{proof}
	We show commutativity first.
	\begin{align*}
		(f \ast g)(x) & = \int_{\R^n} f(x - y)g(y) \d y \\
									& = \int_{\R^n} f(z)g(x - z) \d z	\tag*{using the change \( z = x -y
									\)} \\
									& = \int_{\R^n} g(x - z)f(z) \d z = (g \ast f)(x).
	\end{align*}

	\begin{align*}
		((f \ast g) \ast h)(x) & = \int_{\R^n} (f \ast g)(x - y) h(y) \d y \\
													 & = \int_{\R^n} \left(\int_{\R^n} f(x - z)g(z) \d z\right) h(y) \d y
													 & = 
	\end{align*}

\end{proof}

\part{Banach Spaces}
\chapter{Banach Spaces}
The theory of Banach and Hilbert spaces generalises the basic analytical and geometric
ideas and tools of Euclidean space to a more general class of spaces. By Euclidean space
we mean \( \R^n \) with the topology that is induced by the standard inner product, i.e.
the topology generated by open balls. Our starting point will be normed vector spaces.
From now on \( E \) will denote a vector space over either the real or the complex
numbers. If the distinction is meaningful at any point we will make note of it. We will
refer to elements of the base field simply as scalars, unless whether they are real or
complex is relevant.

\section{Normed spaces}
\begin{definition}[Norm]
	A norm on a vector space \( E \) is a function \( \norm{\cdot} \colon E \to [0, \infty)
	\) such that
	\begin{points}
	\item \( \norm{0} \) if and only if \( x = 0 \),
	\item \( \norm{x + y} \leq \norm{x} + \norm{y} \), which is known as the \emph{triangle
		inequality},
	\item for any scalar \( \lambda \), \( \norm{\lambda x} = \abs{\lambda}\norm{x} \).
	\end{points}
\end{definition}

A vector space equipped with a norm is called a \emph{normed space}. A norm can be used to
define a \emph{metric} or \emph{distance}, which is the function
\begin{align*}
	d \colon E \times E & \longrightarrow [0,\infty) \\
	(x,y) & \longmapsto \norm{x - y}.
\end{align*}
It is easy to check that \( d \) indeed satisfies the definition of a metric:
\begin{points}
\item By definition \( d(x,y) = 0 \) if and only if \( \norm{x - y} = 0 \), which is
	equivalent to \( x - y = 0 \) and thus \( x = y \).
\item \( d(x,y) = \norm{x - y} = \abs{-1}\norm{y - x} = \norm{y - x} = d(y,x) \).
\item \( d(x,y) = \norm{x - z} = \norm{x - y + y - z} \leq \norm{x - y} + \norm{y - z} =
	d(x,y) + d(y,z) \).
\end{points}

We have that a normed space is also a metric space and therefore a topological space, with
the topology generated by the open balls
\begin{equation*}
	B(x,r) \defeq \set{y \in E \mid \norm{x - y} < r}.
\end{equation*}
Thus, a subset \( U \subseteq E \) is open if and only if for every \( x \in E \) there
exists \( r > 0 \) such that \( B(x,r) \subseteq U \).

Note that while a norm always induces a metric, it is not true that every metric comes
from a norm.

There is further structure we could give to our vector space, namely a \emph{scalar
product}. This is a positive definite symmetric bilinear form \( \inn{\cdot}{\cdot} \colon
E \times E \to \R \). This requires that \( E \) be a real vector space. The analog for
complex spaces is a \emph{Hermitian product}, which is a positive definite, conjugate
symmetric bilinear form \( \inn{\cdot}{\cdot} \colon E \times E \to \C \). We will deal
with these later on when discussing Hilbert spaces. For now note that a scalar product
infuces a norm by
\begin{equation*}
	\norm{x} \defeq \sqrt{\inn{x}{x}}.
\end{equation*}

\section{Convergence and completeness}
Since normed spaces are metric spaces we can speak of convergence. 
\begin{definition}[Convergence]
	We say a sequence \( (x_n) \) in a normed space \( E \) \emph{converges} to \( x \in E \) if
	for every \( \epsilon > 0 \) ther exists \( N \in \N \) such that when \( n \geq N \)
	one has
	\begin{equation*}
		\norm{x_n - x} < \epsilon.
	\end{equation*}
\end{definition}
The intuition behind this definition is exactly the same as in the case of Euclidean
space: the terms of the sequence get arbitrarily close to a certain point \( x \) which is
naturally called the \emph{limit} of \( x_n \). We will write \( \lim_{n \to \infty} x_n =
x\) or \( x_n \xrightarrow{n \to \infty} x \) when \( (x_n) \) converges to \( x \).

There is a long list of facts about limits and convergence that are shown for Euclidean
spaces in first and second year Analysis which are also true for any normed space, namely
those that only make use of the normed vector space structure of Euclidean space. Because
of this, their proofs can be repeated verbatim for any normed space. For example, the
limit of a sum is the sum of limits, scalars can move in and out of limits...

An important class of sequences are Cauchy sequences:
\begin{definition}[Cauchy sequence]
	A sequence \( (x_n) \) is a \emph{Cauchy sequence} if for any \( \epsilon > 0 \) there
	exists \( N \in \N \) such that for all \( n, m > N \) one has
	\begin{equation*}
		\norm{x_n - x_m} < \epsilon.
	\end{equation*}
\end{definition}
It is easy to show that a convergent sequence is a Cauchy sequence. Indeed, if \( x_n \to
x\) then for any \( \epsilon > 0 \) there is \( N \in \N \) such that if \( n, m > N \)
\begin{equation*}
	\norm{x_n - x_m} \leq \norm{x_n - x} + \norm{x_m - x} < 2\epsilon.
\end{equation*}
The converse if, of course, not true in general. The most famous offender is of course the
set of real numbers. If there exists a Cauchy sequence that fails to be convergent it
means that our space has a sort of hole. Indeed, the terms of a Cauchy sequence all get
arbitrarily close to each other so if they fail to converge it means they are circling a
point which should be there but isn't.  

A metric space in which every Cauchy sequence is convergent is called \emph{complete}, and
a complete normed space is known as \emph{Banach space}.

\section{Examples}
\begin{example}[Continuous functions on a compact set]
	Let \( K \subseteq \R^n \) be a compact set and consider \( \cont{K} \), the set of
	continuous functions on \( K \). This a vector space with pointwise addition and scalar
	multiplication. We define the norm 
	\begin{equation*}
		\normi{f} \defeq \max_{x \in K} \abs{f(x)}.
	\end{equation*}
	This exists since \( \abs{f} \) is a continuous function on a compact set, thus it
	achieves a maximum value. 
\end{example}

\end{document}

